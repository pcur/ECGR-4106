{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d3f50ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D as Conv2D, MaxPooling2D as MaxPool2D\n",
    "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_flops import get_flops #alternative to ptflops for tensorflow/keras\n",
    "#using keras sequential (or maybe functional API) to create models because I dont like pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc7ff5ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13040a68a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "#bring values between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "plt.imshow(train_images[42069,:,:], cmap='Greys') #display random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26642769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f7e3441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 - 1s - loss: 0.3688 - accuracy: 0.8876\n",
      "\n",
      "Test accuracy: 0.8876000046730042\n",
      "WARNING:tensorflow:From C:\\Users\\curca\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:5063: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOPS: 845862\n"
     ]
    }
   ],
   "source": [
    "#LeNet default Model for comparison\n",
    "\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(6, kernel_size=5, padding = 'same', activation='sigmoid')(inputs)\n",
    "x = layers.AveragePooling2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Conv2D(16, kernel_size=5, activation='relu')(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(120, activation='sigmoid')(x)\n",
    "x = layers.Dense(84, activation='sigmoid')(x)\n",
    "outputs = layers.Dense(10)(x)   \n",
    "\n",
    "LeNet = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "LeNet.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 1.\n",
    "train_hist = LeNet.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 0)\n",
    "\n",
    "LeNet.summary()\n",
    "test_loss, test_acc = LeNet.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(LeNet, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b4f9d",
   "metadata": {},
   "source": [
    "Problem 1 (20pts)\n",
    "\n",
    "Let’s modernize LeNet as we did in the lectures. Implement and test the following changes over FashionMNIST\n",
    "\n",
    "1. Replace the average pooling with max-pooling.\n",
    "2. Replace the softmax layer with ReLU.\n",
    "Start training from scratch based on FashinMNIST. Compare the training loss, training accuracy, and validation accuracy against the baseline we did in the lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43bee72e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# LeNet\n",
    "# Input Layer\n",
    "# LazyConv2D (k 2, padding 2, w sigmoid)\n",
    "# AvgPool2D(k 2, stride 2)\n",
    "# LazyConv2D(k 5, w sigmoid)\n",
    "# AvgPool2D(k 2, stride 2)\n",
    "# Flatten\n",
    "# LazyLinear w sigmoid\n",
    "# LazyLinear w sigmoid\n",
    "# LazyLinear (no acti, output shape)\n",
    "\n",
    "#For Problem 1, assuming 1.2. means replace Sigmoid layer with ReLU as both are activation functions\n",
    "\n",
    "\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(6, kernel_size=5, padding = 'same', activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Conv2D(16, kernel_size=5, activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(120, activation='relu')(x)\n",
    "x = layers.Dense(84, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)   \n",
    "\n",
    "modelp1 = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80e0358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5306 - accuracy: 0.8070 - val_loss: 0.3994 - val_accuracy: 0.8585\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3632 - accuracy: 0.8691 - val_loss: 0.3471 - val_accuracy: 0.8784\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3179 - accuracy: 0.8835 - val_loss: 0.3167 - val_accuracy: 0.8867\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2901 - accuracy: 0.8935 - val_loss: 0.2975 - val_accuracy: 0.8904\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2664 - accuracy: 0.9018 - val_loss: 0.2952 - val_accuracy: 0.8928\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2486 - accuracy: 0.9080 - val_loss: 0.2857 - val_accuracy: 0.8964\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2297 - accuracy: 0.9144 - val_loss: 0.2837 - val_accuracy: 0.8992\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2166 - accuracy: 0.9187 - val_loss: 0.2896 - val_accuracy: 0.9002\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2039 - accuracy: 0.9238 - val_loss: 0.3046 - val_accuracy: 0.8913\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1927 - accuracy: 0.9277 - val_loss: 0.2873 - val_accuracy: 0.8978\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1807 - accuracy: 0.9313 - val_loss: 0.2872 - val_accuracy: 0.9020\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1688 - accuracy: 0.9359 - val_loss: 0.2973 - val_accuracy: 0.9010\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1588 - accuracy: 0.9394 - val_loss: 0.2982 - val_accuracy: 0.9011\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1492 - accuracy: 0.9433 - val_loss: 0.3051 - val_accuracy: 0.9025\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1419 - accuracy: 0.9457 - val_loss: 0.3207 - val_accuracy: 0.9011\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1297 - accuracy: 0.9513 - val_loss: 0.3371 - val_accuracy: 0.9020\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1235 - accuracy: 0.9534 - val_loss: 0.3408 - val_accuracy: 0.9022\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1183 - accuracy: 0.9549 - val_loss: 0.3545 - val_accuracy: 0.9005\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1091 - accuracy: 0.9577 - val_loss: 0.3582 - val_accuracy: 0.8978\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1030 - accuracy: 0.9618 - val_loss: 0.3921 - val_accuracy: 0.8913\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1011 - accuracy: 0.9618 - val_loss: 0.3863 - val_accuracy: 0.9003\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0926 - accuracy: 0.9649 - val_loss: 0.4104 - val_accuracy: 0.9012\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0904 - accuracy: 0.9661 - val_loss: 0.4170 - val_accuracy: 0.8982\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0836 - accuracy: 0.9686 - val_loss: 0.4749 - val_accuracy: 0.8967\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0808 - accuracy: 0.9696 - val_loss: 0.4725 - val_accuracy: 0.8916\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0808 - accuracy: 0.9699 - val_loss: 0.4762 - val_accuracy: 0.8985\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0754 - accuracy: 0.9713 - val_loss: 0.5178 - val_accuracy: 0.8942\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0708 - accuracy: 0.9734 - val_loss: 0.4678 - val_accuracy: 0.8942\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0714 - accuracy: 0.9735 - val_loss: 0.5001 - val_accuracy: 0.8988\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0601 - accuracy: 0.9775 - val_loss: 0.5363 - val_accuracy: 0.8932\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0673 - accuracy: 0.9748 - val_loss: 0.5618 - val_accuracy: 0.8907\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0603 - accuracy: 0.9779 - val_loss: 0.5426 - val_accuracy: 0.8963\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0606 - accuracy: 0.9777 - val_loss: 0.5871 - val_accuracy: 0.8907\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0564 - accuracy: 0.9786 - val_loss: 0.5941 - val_accuracy: 0.8960\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0565 - accuracy: 0.9791 - val_loss: 0.5977 - val_accuracy: 0.8988\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9803 - val_loss: 0.6034 - val_accuracy: 0.8952\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0555 - accuracy: 0.9793 - val_loss: 0.6370 - val_accuracy: 0.8961\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0479 - accuracy: 0.9821 - val_loss: 0.6437 - val_accuracy: 0.8962\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0436 - accuracy: 0.9837 - val_loss: 0.6859 - val_accuracy: 0.8968\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0563 - accuracy: 0.9802 - val_loss: 0.6496 - val_accuracy: 0.8974\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0459 - accuracy: 0.9838 - val_loss: 0.7140 - val_accuracy: 0.8926\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0478 - accuracy: 0.9828 - val_loss: 0.7213 - val_accuracy: 0.8941\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0465 - accuracy: 0.9831 - val_loss: 0.6887 - val_accuracy: 0.8940\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0446 - accuracy: 0.9839 - val_loss: 0.7449 - val_accuracy: 0.8935\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0418 - accuracy: 0.9850 - val_loss: 0.6926 - val_accuracy: 0.8953\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0379 - accuracy: 0.9859 - val_loss: 0.7688 - val_accuracy: 0.8984\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0421 - accuracy: 0.9853 - val_loss: 0.7609 - val_accuracy: 0.8939\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0457 - accuracy: 0.9835 - val_loss: 0.7403 - val_accuracy: 0.8984\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0359 - accuracy: 0.9876 - val_loss: 0.7825 - val_accuracy: 0.8943\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0379 - accuracy: 0.9864 - val_loss: 0.7777 - val_accuracy: 0.8931\n"
     ]
    }
   ],
   "source": [
    "modelp1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 1.\n",
    "train_hist = modelp1.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fb11933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 - 0s - loss: 0.8236 - accuracy: 0.8886\n",
      "\n",
      "Test accuracy: 0.8885999917984009\n",
      "FLOPS: 845862\n"
     ]
    }
   ],
   "source": [
    "modelp1.summary()\n",
    "test_loss, test_acc = modelp1.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(modelp1, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf7b35",
   "metadata": {},
   "source": [
    "Problem 2 (40pts)\n",
    "\n",
    "Try to change the size of the LeNet style network to improve its accuracy in addition to max-pooling and ReLU.\n",
    "\n",
    "1. Adjust the convolution window size.\n",
    "2. Adjust the number of output channels (width of each layer).\n",
    "3. Adjust the number of convolution layers.\n",
    "4. Adjust the number of fully connected layers.\n",
    "5. Explore the learning rates.\n",
    "\n",
    "For all training adjustments, restart training from scratch based on FashinMNIST. Compare the training loss, training accuracy, and validation accuracy against each other and the baseline in problem 1. Argue which adjustment presents the better benefit and generalization. Measure and compare theoretical computation complexity (number of operations and parameters size) using ptflops https://pypi.org/project/ptflops/\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "543fa661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 2, part 1 - Changing convolution window size (decreasing kernel size)\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(6, kernel_size=3, padding = 'same', activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Conv2D(16, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(120, activation='relu')(x)\n",
    "x = layers.Dense(84, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)   \n",
    "\n",
    "modelp2_1 = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e111c0e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5187 - accuracy: 0.8128 - val_loss: 0.3993 - val_accuracy: 0.8532\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3541 - accuracy: 0.8704 - val_loss: 0.3298 - val_accuracy: 0.8810\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3061 - accuracy: 0.8870 - val_loss: 0.3129 - val_accuracy: 0.8864\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2765 - accuracy: 0.8966 - val_loss: 0.2856 - val_accuracy: 0.8947\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2543 - accuracy: 0.9057 - val_loss: 0.2819 - val_accuracy: 0.8963\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2377 - accuracy: 0.9101 - val_loss: 0.2770 - val_accuracy: 0.9007\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2212 - accuracy: 0.9167 - val_loss: 0.2740 - val_accuracy: 0.9018\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2052 - accuracy: 0.9221 - val_loss: 0.2606 - val_accuracy: 0.9062\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1908 - accuracy: 0.9272 - val_loss: 0.2618 - val_accuracy: 0.9068\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1782 - accuracy: 0.9322 - val_loss: 0.2818 - val_accuracy: 0.9026\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1681 - accuracy: 0.9363 - val_loss: 0.2688 - val_accuracy: 0.9069\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1557 - accuracy: 0.9418 - val_loss: 0.2753 - val_accuracy: 0.9072\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1465 - accuracy: 0.9439 - val_loss: 0.2933 - val_accuracy: 0.9056\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1359 - accuracy: 0.9475 - val_loss: 0.3021 - val_accuracy: 0.9071\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1277 - accuracy: 0.9510 - val_loss: 0.3040 - val_accuracy: 0.9072\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1158 - accuracy: 0.9548 - val_loss: 0.3302 - val_accuracy: 0.9050\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1116 - accuracy: 0.9576 - val_loss: 0.3355 - val_accuracy: 0.9045\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1017 - accuracy: 0.9607 - val_loss: 0.3246 - val_accuracy: 0.9078\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0957 - accuracy: 0.9627 - val_loss: 0.3638 - val_accuracy: 0.9045\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0886 - accuracy: 0.9665 - val_loss: 0.3877 - val_accuracy: 0.9056\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0834 - accuracy: 0.9686 - val_loss: 0.4128 - val_accuracy: 0.9016\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0779 - accuracy: 0.9710 - val_loss: 0.4199 - val_accuracy: 0.9001\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0723 - accuracy: 0.9726 - val_loss: 0.4320 - val_accuracy: 0.9042\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0694 - accuracy: 0.9737 - val_loss: 0.4773 - val_accuracy: 0.8999\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0644 - accuracy: 0.9753 - val_loss: 0.4642 - val_accuracy: 0.9046\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0600 - accuracy: 0.9771 - val_loss: 0.5064 - val_accuracy: 0.9032\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0554 - accuracy: 0.9796 - val_loss: 0.5391 - val_accuracy: 0.9010\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0553 - accuracy: 0.9796 - val_loss: 0.5151 - val_accuracy: 0.9038\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0480 - accuracy: 0.9816 - val_loss: 0.5320 - val_accuracy: 0.9001\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0461 - accuracy: 0.9827 - val_loss: 0.5462 - val_accuracy: 0.9041\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0470 - accuracy: 0.9829 - val_loss: 0.6119 - val_accuracy: 0.9010\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0433 - accuracy: 0.9840 - val_loss: 0.6055 - val_accuracy: 0.8954\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0420 - accuracy: 0.9843 - val_loss: 0.5922 - val_accuracy: 0.9035\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0386 - accuracy: 0.9854 - val_loss: 0.6964 - val_accuracy: 0.8886\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0403 - accuracy: 0.9849 - val_loss: 0.6317 - val_accuracy: 0.9018\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0381 - accuracy: 0.9859 - val_loss: 0.6683 - val_accuracy: 0.9005\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0394 - accuracy: 0.9850 - val_loss: 0.6337 - val_accuracy: 0.9029\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0333 - accuracy: 0.9877 - val_loss: 0.6972 - val_accuracy: 0.9000\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0367 - accuracy: 0.9867 - val_loss: 0.6472 - val_accuracy: 0.9043\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0320 - accuracy: 0.9887 - val_loss: 0.6623 - val_accuracy: 0.9047\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0340 - accuracy: 0.9879 - val_loss: 0.7273 - val_accuracy: 0.8990\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 0.7598 - val_accuracy: 0.9038\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.7267 - val_accuracy: 0.9009\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0353 - accuracy: 0.9880 - val_loss: 0.7281 - val_accuracy: 0.9038\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0233 - accuracy: 0.9913 - val_loss: 0.7760 - val_accuracy: 0.9047\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0323 - accuracy: 0.9883 - val_loss: 0.7979 - val_accuracy: 0.8988\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0259 - accuracy: 0.9907 - val_loss: 0.7770 - val_accuracy: 0.9042\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0266 - accuracy: 0.9901 - val_loss: 0.7896 - val_accuracy: 0.9029\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0280 - accuracy: 0.9898 - val_loss: 0.8341 - val_accuracy: 0.9028\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0268 - accuracy: 0.9909 - val_loss: 0.8125 - val_accuracy: 0.8994\n"
     ]
    }
   ],
   "source": [
    "modelp2_1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 1.\n",
    "train_hist = modelp2_1.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe93243a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 6)         60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 16)        880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 81,194\n",
      "Trainable params: 81,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 - 0s - loss: 0.8592 - accuracy: 0.8945\n",
      "\n",
      "Test accuracy: 0.8945000171661377\n",
      "FLOPS: 507814\n"
     ]
    }
   ],
   "source": [
    "modelp2_1.summary()\n",
    "test_loss, test_acc = modelp2_1.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(modelp2_1, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37828596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 2, part 2 - Changing layer widths (increasing generally)\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(32, kernel_size=5, padding = 'same', activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Conv2D(64, kernel_size=5, activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)   \n",
    "\n",
    "modelp2_2 = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54d6793d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4849 - accuracy: 0.8234 - val_loss: 0.3279 - val_accuracy: 0.8836\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3072 - accuracy: 0.8890 - val_loss: 0.2948 - val_accuracy: 0.8913\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2577 - accuracy: 0.9070 - val_loss: 0.2777 - val_accuracy: 0.8983\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2275 - accuracy: 0.9161 - val_loss: 0.2711 - val_accuracy: 0.9018\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2025 - accuracy: 0.9248 - val_loss: 0.2416 - val_accuracy: 0.9111\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1824 - accuracy: 0.9325 - val_loss: 0.2468 - val_accuracy: 0.9124\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1617 - accuracy: 0.9396 - val_loss: 0.3108 - val_accuracy: 0.9078\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1484 - accuracy: 0.9438 - val_loss: 0.2414 - val_accuracy: 0.9151\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1285 - accuracy: 0.9519 - val_loss: 0.2741 - val_accuracy: 0.9128\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1168 - accuracy: 0.9563 - val_loss: 0.2845 - val_accuracy: 0.9160\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1044 - accuracy: 0.9606 - val_loss: 0.2918 - val_accuracy: 0.9111\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0943 - accuracy: 0.9650 - val_loss: 0.2752 - val_accuracy: 0.9167\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0815 - accuracy: 0.9693 - val_loss: 0.3326 - val_accuracy: 0.9155\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0767 - accuracy: 0.9710 - val_loss: 0.3612 - val_accuracy: 0.9153\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0706 - accuracy: 0.9734 - val_loss: 0.3403 - val_accuracy: 0.9144\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0613 - accuracy: 0.9772 - val_loss: 0.3846 - val_accuracy: 0.9058\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0592 - accuracy: 0.9777 - val_loss: 0.4315 - val_accuracy: 0.9125\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0605 - accuracy: 0.9780 - val_loss: 0.4030 - val_accuracy: 0.9115\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0487 - accuracy: 0.9815 - val_loss: 0.4521 - val_accuracy: 0.9124\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0452 - accuracy: 0.9830 - val_loss: 0.4353 - val_accuracy: 0.9156\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0491 - accuracy: 0.9820 - val_loss: 0.4145 - val_accuracy: 0.9168\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0434 - accuracy: 0.9842 - val_loss: 0.4625 - val_accuracy: 0.9165\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0399 - accuracy: 0.9856 - val_loss: 0.4899 - val_accuracy: 0.9169\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0380 - accuracy: 0.9865 - val_loss: 0.5726 - val_accuracy: 0.9080\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0368 - accuracy: 0.9867 - val_loss: 0.4923 - val_accuracy: 0.9111\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0363 - accuracy: 0.9871 - val_loss: 0.5220 - val_accuracy: 0.9082\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0341 - accuracy: 0.9885 - val_loss: 0.5563 - val_accuracy: 0.9095\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9890 - val_loss: 0.6436 - val_accuracy: 0.9062\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0373 - accuracy: 0.9871 - val_loss: 0.6014 - val_accuracy: 0.9111\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0312 - accuracy: 0.9889 - val_loss: 0.6336 - val_accuracy: 0.9106\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0312 - accuracy: 0.9893 - val_loss: 0.5504 - val_accuracy: 0.9107\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0274 - accuracy: 0.9900 - val_loss: 0.5432 - val_accuracy: 0.9130\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.5997 - val_accuracy: 0.9119\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0270 - accuracy: 0.9906 - val_loss: 0.6163 - val_accuracy: 0.9153\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.6271 - val_accuracy: 0.9132\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0296 - accuracy: 0.9897 - val_loss: 0.6036 - val_accuracy: 0.9099\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0302 - accuracy: 0.9904 - val_loss: 0.7128 - val_accuracy: 0.9138\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0191 - accuracy: 0.9930 - val_loss: 0.6804 - val_accuracy: 0.9093\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0261 - accuracy: 0.9910 - val_loss: 0.6531 - val_accuracy: 0.9112\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.6851 - val_accuracy: 0.9123\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.6300 - val_accuracy: 0.9103\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.6800 - val_accuracy: 0.9120\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 0.7323 - val_accuracy: 0.9079\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.7639 - val_accuracy: 0.9034\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.6738 - val_accuracy: 0.9053\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.7011 - val_accuracy: 0.9127\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.6752 - val_accuracy: 0.9128\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.6701 - val_accuracy: 0.9140\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.7140 - val_accuracy: 0.9141\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.6620 - val_accuracy: 0.9141\n"
     ]
    }
   ],
   "source": [
    "modelp2_2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 1.\n",
    "train_hist = modelp2_2.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "188b0ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 10, 10, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 265,930\n",
      "Trainable params: 265,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 - 1s - loss: 0.7506 - accuracy: 0.9105\n",
      "\n",
      "Test accuracy: 0.9104999899864197\n",
      "FLOPS: 11984842\n"
     ]
    }
   ],
   "source": [
    "modelp2_2.summary()\n",
    "test_loss, test_acc = modelp2_2.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(modelp2_2, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cbbc95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 2, part 3 - Changing number of convolution layers (2 extra)\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(6, kernel_size=5, padding = 'same', activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Conv2D(16, kernel_size=5, padding = 'same', activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Conv2D(32, kernel_size=5, padding = 'same', activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Conv2D(64, kernel_size=5, padding = 'same', activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(120, activation='relu')(x)\n",
    "x = layers.Dense(84, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)   \n",
    "\n",
    "modelp2_3 = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d023ee9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.6171 - accuracy: 0.7651 - val_loss: 0.4470 - val_accuracy: 0.8414\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3885 - accuracy: 0.8584 - val_loss: 0.3759 - val_accuracy: 0.8593\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3346 - accuracy: 0.8772 - val_loss: 0.3324 - val_accuracy: 0.8785\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3022 - accuracy: 0.8882 - val_loss: 0.3016 - val_accuracy: 0.8910\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2783 - accuracy: 0.8958 - val_loss: 0.2856 - val_accuracy: 0.8963\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2573 - accuracy: 0.9038 - val_loss: 0.2974 - val_accuracy: 0.8932\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2396 - accuracy: 0.9105 - val_loss: 0.2717 - val_accuracy: 0.9033\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2277 - accuracy: 0.9153 - val_loss: 0.2823 - val_accuracy: 0.8981\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2166 - accuracy: 0.9191 - val_loss: 0.2792 - val_accuracy: 0.9010\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2018 - accuracy: 0.9248 - val_loss: 0.2727 - val_accuracy: 0.9057\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1908 - accuracy: 0.9281 - val_loss: 0.2831 - val_accuracy: 0.9002\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1822 - accuracy: 0.9311 - val_loss: 0.2818 - val_accuracy: 0.9074\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1718 - accuracy: 0.9351 - val_loss: 0.2916 - val_accuracy: 0.9003\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1621 - accuracy: 0.9381 - val_loss: 0.2861 - val_accuracy: 0.9062\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1565 - accuracy: 0.9406 - val_loss: 0.2995 - val_accuracy: 0.9028\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1482 - accuracy: 0.9431 - val_loss: 0.3049 - val_accuracy: 0.8984\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1403 - accuracy: 0.9466 - val_loss: 0.3331 - val_accuracy: 0.9023\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1346 - accuracy: 0.9495 - val_loss: 0.3226 - val_accuracy: 0.9010\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1303 - accuracy: 0.9499 - val_loss: 0.3680 - val_accuracy: 0.9008\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1265 - accuracy: 0.9513 - val_loss: 0.3341 - val_accuracy: 0.9048\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1202 - accuracy: 0.9539 - val_loss: 0.3728 - val_accuracy: 0.8933\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1190 - accuracy: 0.9542 - val_loss: 0.3569 - val_accuracy: 0.9006\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1103 - accuracy: 0.9575 - val_loss: 0.3877 - val_accuracy: 0.8992\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1071 - accuracy: 0.9594 - val_loss: 0.3757 - val_accuracy: 0.9035\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1042 - accuracy: 0.9608 - val_loss: 0.3658 - val_accuracy: 0.9023\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0999 - accuracy: 0.9613 - val_loss: 0.4091 - val_accuracy: 0.8939\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0970 - accuracy: 0.9633 - val_loss: 0.4214 - val_accuracy: 0.9014\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0914 - accuracy: 0.9649 - val_loss: 0.4298 - val_accuracy: 0.9023\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0893 - accuracy: 0.9666 - val_loss: 0.4233 - val_accuracy: 0.9014\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0856 - accuracy: 0.9673 - val_loss: 0.4558 - val_accuracy: 0.8966\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0804 - accuracy: 0.9695 - val_loss: 0.4732 - val_accuracy: 0.8922\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0835 - accuracy: 0.9690 - val_loss: 0.4212 - val_accuracy: 0.8968\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0785 - accuracy: 0.9699 - val_loss: 0.4619 - val_accuracy: 0.9002\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0767 - accuracy: 0.9715 - val_loss: 0.4731 - val_accuracy: 0.8972\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0753 - accuracy: 0.9711 - val_loss: 0.4512 - val_accuracy: 0.8987\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0727 - accuracy: 0.9727 - val_loss: 0.5044 - val_accuracy: 0.9005\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0705 - accuracy: 0.9739 - val_loss: 0.4663 - val_accuracy: 0.9009\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0712 - accuracy: 0.9730 - val_loss: 0.5163 - val_accuracy: 0.9013\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0646 - accuracy: 0.9760 - val_loss: 0.5259 - val_accuracy: 0.8919\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0669 - accuracy: 0.9748 - val_loss: 0.4833 - val_accuracy: 0.8985\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0632 - accuracy: 0.9766 - val_loss: 0.5550 - val_accuracy: 0.8942\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0631 - accuracy: 0.9770 - val_loss: 0.5059 - val_accuracy: 0.9039\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0606 - accuracy: 0.9773 - val_loss: 0.4908 - val_accuracy: 0.8998\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0613 - accuracy: 0.9774 - val_loss: 0.5662 - val_accuracy: 0.9036\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0579 - accuracy: 0.9786 - val_loss: 0.5399 - val_accuracy: 0.8992\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0598 - accuracy: 0.9782 - val_loss: 0.5435 - val_accuracy: 0.9004\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0589 - accuracy: 0.9785 - val_loss: 0.5532 - val_accuracy: 0.8992\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0583 - accuracy: 0.9792 - val_loss: 0.5592 - val_accuracy: 0.8957\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0565 - accuracy: 0.9807 - val_loss: 0.5409 - val_accuracy: 0.8978\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0529 - accuracy: 0.9815 - val_loss: 0.6070 - val_accuracy: 0.8961\n"
     ]
    }
   ],
   "source": [
    "modelp2_3.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 1.\n",
    "train_hist = modelp2_3.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f087f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 7, 7, 32)          12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 3, 3, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 120)               7800      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 85,482\n",
      "Trainable params: 85,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 - 1s - loss: 0.6278 - accuracy: 0.8952\n",
      "\n",
      "Test accuracy: 0.8952000141143799\n",
      "FLOPS: 3408646\n"
     ]
    }
   ],
   "source": [
    "modelp2_3.summary()\n",
    "test_loss, test_acc = modelp2_3.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(modelp2_3, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "516f26ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 2, part 4 - Changing number of fully connected (dense) layers (2 extra)\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(6, kernel_size=5, padding = 'same', activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Conv2D(16, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(120, activation='relu')(x)\n",
    "x = layers.Dense(120, activation='relu')(x)\n",
    "x = layers.Dense(120, activation='relu')(x)\n",
    "x = layers.Dense(84, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)   \n",
    "\n",
    "modelp2_4 = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1146c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5487 - accuracy: 0.7976 - val_loss: 0.4251 - val_accuracy: 0.8478\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3545 - accuracy: 0.8683 - val_loss: 0.3573 - val_accuracy: 0.8664\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3074 - accuracy: 0.8865 - val_loss: 0.3067 - val_accuracy: 0.8867\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2774 - accuracy: 0.8981 - val_loss: 0.2782 - val_accuracy: 0.8992\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2543 - accuracy: 0.9055 - val_loss: 0.2963 - val_accuracy: 0.8937\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2389 - accuracy: 0.9112 - val_loss: 0.2835 - val_accuracy: 0.8983\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2173 - accuracy: 0.9180 - val_loss: 0.2630 - val_accuracy: 0.9044\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2045 - accuracy: 0.9245 - val_loss: 0.2760 - val_accuracy: 0.9005\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1925 - accuracy: 0.9281 - val_loss: 0.2662 - val_accuracy: 0.9043\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1785 - accuracy: 0.9326 - val_loss: 0.2901 - val_accuracy: 0.8967\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1666 - accuracy: 0.9370 - val_loss: 0.2853 - val_accuracy: 0.9035\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1590 - accuracy: 0.9399 - val_loss: 0.2797 - val_accuracy: 0.9069\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1491 - accuracy: 0.9449 - val_loss: 0.2969 - val_accuracy: 0.9037\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1413 - accuracy: 0.9472 - val_loss: 0.3004 - val_accuracy: 0.8995\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1277 - accuracy: 0.9511 - val_loss: 0.3372 - val_accuracy: 0.9005\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1255 - accuracy: 0.9528 - val_loss: 0.3166 - val_accuracy: 0.9067\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1149 - accuracy: 0.9556 - val_loss: 0.3299 - val_accuracy: 0.9013\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1090 - accuracy: 0.9590 - val_loss: 0.3329 - val_accuracy: 0.9039\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1052 - accuracy: 0.9613 - val_loss: 0.3439 - val_accuracy: 0.9068\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0967 - accuracy: 0.9644 - val_loss: 0.3712 - val_accuracy: 0.9005\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0916 - accuracy: 0.9650 - val_loss: 0.3871 - val_accuracy: 0.9036\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0905 - accuracy: 0.9661 - val_loss: 0.3990 - val_accuracy: 0.9079\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0844 - accuracy: 0.9681 - val_loss: 0.3889 - val_accuracy: 0.9040\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0776 - accuracy: 0.9712 - val_loss: 0.4123 - val_accuracy: 0.9089\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0734 - accuracy: 0.9730 - val_loss: 0.4439 - val_accuracy: 0.9043\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0731 - accuracy: 0.9732 - val_loss: 0.4344 - val_accuracy: 0.9041\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0688 - accuracy: 0.9744 - val_loss: 0.4677 - val_accuracy: 0.9024\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0650 - accuracy: 0.9759 - val_loss: 0.4597 - val_accuracy: 0.9039\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0661 - accuracy: 0.9761 - val_loss: 0.4601 - val_accuracy: 0.9057\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0604 - accuracy: 0.9780 - val_loss: 0.4720 - val_accuracy: 0.9048\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0607 - accuracy: 0.9776 - val_loss: 0.4604 - val_accuracy: 0.9047\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0575 - accuracy: 0.9789 - val_loss: 0.5666 - val_accuracy: 0.9039\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0551 - accuracy: 0.9798 - val_loss: 0.5081 - val_accuracy: 0.9018\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0522 - accuracy: 0.9815 - val_loss: 0.5184 - val_accuracy: 0.9054\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0521 - accuracy: 0.9815 - val_loss: 0.4821 - val_accuracy: 0.9021\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0490 - accuracy: 0.9827 - val_loss: 0.5422 - val_accuracy: 0.9042\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0495 - accuracy: 0.9827 - val_loss: 0.5113 - val_accuracy: 0.9031\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0481 - accuracy: 0.9831 - val_loss: 0.5313 - val_accuracy: 0.9052\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0431 - accuracy: 0.9846 - val_loss: 0.5421 - val_accuracy: 0.9005\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0465 - accuracy: 0.9827 - val_loss: 0.5370 - val_accuracy: 0.9027\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0434 - accuracy: 0.9847 - val_loss: 0.5503 - val_accuracy: 0.9056\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0412 - accuracy: 0.9853 - val_loss: 0.5436 - val_accuracy: 0.8980\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0407 - accuracy: 0.9862 - val_loss: 0.6248 - val_accuracy: 0.9037\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0384 - accuracy: 0.9865 - val_loss: 0.5559 - val_accuracy: 0.9081\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0373 - accuracy: 0.9864 - val_loss: 0.6292 - val_accuracy: 0.9051\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0390 - accuracy: 0.9857 - val_loss: 0.6365 - val_accuracy: 0.9038\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0357 - accuracy: 0.9872 - val_loss: 0.6427 - val_accuracy: 0.9053\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0395 - accuracy: 0.9864 - val_loss: 0.5693 - val_accuracy: 0.9045\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0344 - accuracy: 0.9883 - val_loss: 0.6620 - val_accuracy: 0.9002\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 0.6661 - val_accuracy: 0.8978\n"
     ]
    }
   ],
   "source": [
    "modelp2_4.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 1.\n",
    "train_hist = modelp2_4.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "512052aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 12, 12, 16)        880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 110,330\n",
      "Trainable params: 110,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 - 1s - loss: 0.7167 - accuracy: 0.8960\n",
      "\n",
      "Test accuracy: 0.8960000276565552\n",
      "FLOPS: 716182\n"
     ]
    }
   ],
   "source": [
    "modelp2_4.summary()\n",
    "test_loss, test_acc = modelp2_4.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(modelp2_4, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "001b04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 2, part 5 - Changing learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dccc2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(6, kernel_size=5, padding = 'same', activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Conv2D(16, kernel_size=5, activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(120, activation='relu')(x)\n",
    "x = layers.Dense(84, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)   \n",
    "\n",
    "modelp2_5 = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4ec268e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.4735 - accuracy: 0.8266 - val_loss: 0.3612 - val_accuracy: 0.8669\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3418 - accuracy: 0.8727 - val_loss: 0.3331 - val_accuracy: 0.8817\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3143 - accuracy: 0.8836 - val_loss: 0.3131 - val_accuracy: 0.8874\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2996 - accuracy: 0.8900 - val_loss: 0.3514 - val_accuracy: 0.8728\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2902 - accuracy: 0.8936 - val_loss: 0.3169 - val_accuracy: 0.8839\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2796 - accuracy: 0.8973 - val_loss: 0.3108 - val_accuracy: 0.8873\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2704 - accuracy: 0.9006 - val_loss: 0.3214 - val_accuracy: 0.8888\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2677 - accuracy: 0.9028 - val_loss: 0.3102 - val_accuracy: 0.8947\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2632 - accuracy: 0.9023 - val_loss: 0.3181 - val_accuracy: 0.8845\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2582 - accuracy: 0.9050 - val_loss: 0.3337 - val_accuracy: 0.8827\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2463 - accuracy: 0.9102 - val_loss: 0.3487 - val_accuracy: 0.8866\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2570 - accuracy: 0.9080 - val_loss: 0.3937 - val_accuracy: 0.8733\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2470 - accuracy: 0.9087 - val_loss: 0.3510 - val_accuracy: 0.8833\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2479 - accuracy: 0.9096 - val_loss: 0.3331 - val_accuracy: 0.8813\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2350 - accuracy: 0.9137 - val_loss: 0.3390 - val_accuracy: 0.8910\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2316 - accuracy: 0.9147 - val_loss: 0.3529 - val_accuracy: 0.8873\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2321 - accuracy: 0.9146 - val_loss: 0.3554 - val_accuracy: 0.8898\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2319 - accuracy: 0.9158 - val_loss: 0.3750 - val_accuracy: 0.8813\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2343 - accuracy: 0.9157 - val_loss: 0.3624 - val_accuracy: 0.8800\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2275 - accuracy: 0.9177 - val_loss: 0.3387 - val_accuracy: 0.8948\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2173 - accuracy: 0.9209 - val_loss: 0.3587 - val_accuracy: 0.8927\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2239 - accuracy: 0.9208 - val_loss: 0.3819 - val_accuracy: 0.8917\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2288 - accuracy: 0.9201 - val_loss: 0.3697 - val_accuracy: 0.8851\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2100 - accuracy: 0.9261 - val_loss: 0.3400 - val_accuracy: 0.8951\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2102 - accuracy: 0.9244 - val_loss: 0.3521 - val_accuracy: 0.8923\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2148 - accuracy: 0.9237 - val_loss: 0.3728 - val_accuracy: 0.8853\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2275 - accuracy: 0.9198 - val_loss: 0.4208 - val_accuracy: 0.8832\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2044 - accuracy: 0.9270 - val_loss: 0.3755 - val_accuracy: 0.8969\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2057 - accuracy: 0.9273 - val_loss: 0.3764 - val_accuracy: 0.8898\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2081 - accuracy: 0.9270 - val_loss: 0.3840 - val_accuracy: 0.8924\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1986 - accuracy: 0.9287 - val_loss: 0.3872 - val_accuracy: 0.8957\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1912 - accuracy: 0.9316 - val_loss: 0.5028 - val_accuracy: 0.8801\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2042 - accuracy: 0.9284 - val_loss: 0.4253 - val_accuracy: 0.8867\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1985 - accuracy: 0.9303 - val_loss: 0.3857 - val_accuracy: 0.8942\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2162 - accuracy: 0.9255 - val_loss: 0.3986 - val_accuracy: 0.8971\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2141 - accuracy: 0.9254 - val_loss: 0.4256 - val_accuracy: 0.8965\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2016 - accuracy: 0.9296 - val_loss: 0.4155 - val_accuracy: 0.8910\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1980 - accuracy: 0.9313 - val_loss: 0.4644 - val_accuracy: 0.8916\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1901 - accuracy: 0.9316 - val_loss: 0.5115 - val_accuracy: 0.8908\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2310 - accuracy: 0.9217 - val_loss: 0.4398 - val_accuracy: 0.8954\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1944 - accuracy: 0.9319 - val_loss: 0.4770 - val_accuracy: 0.8913\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1940 - accuracy: 0.9334 - val_loss: 0.4721 - val_accuracy: 0.8957\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1842 - accuracy: 0.9354 - val_loss: 0.4934 - val_accuracy: 0.8982\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2148 - accuracy: 0.9294 - val_loss: 0.4679 - val_accuracy: 0.8812\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1850 - accuracy: 0.9358 - val_loss: 0.4632 - val_accuracy: 0.8922\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2010 - accuracy: 0.9324 - val_loss: 0.4932 - val_accuracy: 0.8878\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1928 - accuracy: 0.9353 - val_loss: 0.5297 - val_accuracy: 0.8803\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1835 - accuracy: 0.9364 - val_loss: 0.5102 - val_accuracy: 0.8882\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2128 - accuracy: 0.9308 - val_loss: 0.5194 - val_accuracy: 0.8925\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2121 - accuracy: 0.9309 - val_loss: 0.5097 - val_accuracy: 0.8888\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.005) #default LR of 0.001\n",
    "\n",
    "modelp2_5.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 1.\n",
    "train_hist = modelp2_5.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e5cbcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 - 0s - loss: 0.6020 - accuracy: 0.8777\n",
      "\n",
      "Test accuracy: 0.8776999711990356\n",
      "FLOPS: 845862\n"
     ]
    }
   ],
   "source": [
    "modelp2_5.summary()\n",
    "test_loss, test_acc = modelp2_5.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(modelp2_5, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82811636",
   "metadata": {},
   "source": [
    "Problem 3 (10pts)\n",
    "\n",
    "Pick the best model from problem 2. Apply dropout to LeNet-5 across all experiments in problem 2. Does it improve the training? For all training adjustments, restart training from scratch based on FashinMNIST. Compare the training loss, training accuracy, and validation accuracy against the best model in problem 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ecc042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 3, part 1 - Changing convolution window size (decreasing kernel size)\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(6, kernel_size=3, padding = 'same', activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Conv2D(16, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(120, activation='relu')(x)\n",
    "x = layers.Dense(84, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)   \n",
    "\n",
    "modelp3_1 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "#Problem 3, part 2 - Changing layer widths (increasing generally)\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(32, kernel_size=5, padding = 'same', activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Conv2D(64, kernel_size=5, activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)   \n",
    "\n",
    "modelp3_2 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "#Problem 2, part 3 - Changing number of convolution layers (2 extra)\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(6, kernel_size=5, padding = 'same', activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Conv2D(16, kernel_size=5, padding = 'same', activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Conv2D(32, kernel_size=5, padding = 'same', activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Conv2D(64, kernel_size=5, padding = 'same', activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(120, activation='relu')(x)\n",
    "x = layers.Dense(84, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)   \n",
    "\n",
    "modelp3_3 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "#Problem 3, part 4 - Changing number of fully connected (dense) layers (2 extra)\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(6, kernel_size=5, padding = 'same', activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Conv2D(16, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(120, activation='relu')(x)\n",
    "x = layers.Dense(120, activation='relu')(x)\n",
    "x = layers.Dense(120, activation='relu')(x)\n",
    "x = layers.Dense(84, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)   \n",
    "\n",
    "modelp3_4 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "#Problem 3, part 5 - Changing learning rate\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(6, kernel_size=5, padding = 'same', activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Conv2D(16, kernel_size=5, activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(120, activation='relu')(x)\n",
    "x = layers.Dense(84, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)   \n",
    "\n",
    "modelp3_5 = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c2b46eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 - 4s - loss: 0.6385 - accuracy: 0.7605 - val_loss: 0.4519 - val_accuracy: 0.8439\n",
      "Epoch 2/50\n",
      "1500/1500 - 3s - loss: 0.4292 - accuracy: 0.8410 - val_loss: 0.3562 - val_accuracy: 0.8705\n",
      "Epoch 3/50\n",
      "1500/1500 - 3s - loss: 0.3834 - accuracy: 0.8581 - val_loss: 0.3301 - val_accuracy: 0.8792\n",
      "Epoch 4/50\n",
      "1500/1500 - 3s - loss: 0.3536 - accuracy: 0.8694 - val_loss: 0.3179 - val_accuracy: 0.8823\n",
      "Epoch 5/50\n",
      "1500/1500 - 3s - loss: 0.3353 - accuracy: 0.8749 - val_loss: 0.3073 - val_accuracy: 0.8864\n",
      "Epoch 6/50\n",
      "1500/1500 - 3s - loss: 0.3203 - accuracy: 0.8796 - val_loss: 0.2850 - val_accuracy: 0.8964\n",
      "Epoch 7/50\n",
      "1500/1500 - 3s - loss: 0.3093 - accuracy: 0.8848 - val_loss: 0.2841 - val_accuracy: 0.8976\n",
      "Epoch 8/50\n",
      "1500/1500 - 3s - loss: 0.2991 - accuracy: 0.8882 - val_loss: 0.2723 - val_accuracy: 0.9002\n",
      "Epoch 9/50\n",
      "1500/1500 - 3s - loss: 0.2918 - accuracy: 0.8916 - val_loss: 0.2935 - val_accuracy: 0.8898\n",
      "Epoch 10/50\n",
      "1500/1500 - 3s - loss: 0.2860 - accuracy: 0.8924 - val_loss: 0.2630 - val_accuracy: 0.9029\n",
      "Epoch 11/50\n",
      "1500/1500 - 3s - loss: 0.2739 - accuracy: 0.8970 - val_loss: 0.2512 - val_accuracy: 0.9068\n",
      "Epoch 12/50\n",
      "1500/1500 - 3s - loss: 0.2701 - accuracy: 0.9003 - val_loss: 0.2703 - val_accuracy: 0.9017\n",
      "Epoch 13/50\n",
      "1500/1500 - 3s - loss: 0.2651 - accuracy: 0.9006 - val_loss: 0.2596 - val_accuracy: 0.9038\n",
      "Epoch 14/50\n",
      "1500/1500 - 3s - loss: 0.2563 - accuracy: 0.9034 - val_loss: 0.2524 - val_accuracy: 0.9046\n",
      "Epoch 15/50\n",
      "1500/1500 - 3s - loss: 0.2557 - accuracy: 0.9039 - val_loss: 0.2445 - val_accuracy: 0.9080\n",
      "Epoch 16/50\n",
      "1500/1500 - 3s - loss: 0.2494 - accuracy: 0.9062 - val_loss: 0.2506 - val_accuracy: 0.9053\n",
      "Epoch 17/50\n",
      "1500/1500 - 3s - loss: 0.2447 - accuracy: 0.9076 - val_loss: 0.2345 - val_accuracy: 0.9114\n",
      "Epoch 18/50\n",
      "1500/1500 - 3s - loss: 0.2435 - accuracy: 0.9086 - val_loss: 0.2472 - val_accuracy: 0.9092\n",
      "Epoch 19/50\n",
      "1500/1500 - 3s - loss: 0.2408 - accuracy: 0.9084 - val_loss: 0.2455 - val_accuracy: 0.9087\n",
      "Epoch 20/50\n",
      "1500/1500 - 3s - loss: 0.2347 - accuracy: 0.9113 - val_loss: 0.2380 - val_accuracy: 0.9134\n",
      "Epoch 21/50\n",
      "1500/1500 - 3s - loss: 0.2283 - accuracy: 0.9136 - val_loss: 0.2437 - val_accuracy: 0.9096\n",
      "Epoch 22/50\n",
      "1500/1500 - 3s - loss: 0.2326 - accuracy: 0.9123 - val_loss: 0.2390 - val_accuracy: 0.9103\n",
      "Epoch 23/50\n",
      "1500/1500 - 3s - loss: 0.2287 - accuracy: 0.9132 - val_loss: 0.2454 - val_accuracy: 0.9083\n",
      "Epoch 24/50\n",
      "1500/1500 - 3s - loss: 0.2216 - accuracy: 0.9160 - val_loss: 0.2547 - val_accuracy: 0.9057\n",
      "Epoch 25/50\n",
      "1500/1500 - 3s - loss: 0.2235 - accuracy: 0.9146 - val_loss: 0.2441 - val_accuracy: 0.9099\n",
      "Epoch 26/50\n",
      "1500/1500 - 3s - loss: 0.2255 - accuracy: 0.9145 - val_loss: 0.2321 - val_accuracy: 0.9134\n",
      "Epoch 27/50\n",
      "1500/1500 - 3s - loss: 0.2185 - accuracy: 0.9164 - val_loss: 0.2270 - val_accuracy: 0.9158\n",
      "Epoch 28/50\n",
      "1500/1500 - 3s - loss: 0.2202 - accuracy: 0.9155 - val_loss: 0.2309 - val_accuracy: 0.9127\n",
      "Epoch 29/50\n",
      "1500/1500 - 3s - loss: 0.2167 - accuracy: 0.9175 - val_loss: 0.2321 - val_accuracy: 0.9137\n",
      "Epoch 30/50\n",
      "1500/1500 - 3s - loss: 0.2142 - accuracy: 0.9191 - val_loss: 0.2314 - val_accuracy: 0.9137\n",
      "Epoch 31/50\n",
      "1500/1500 - 3s - loss: 0.2142 - accuracy: 0.9189 - val_loss: 0.2268 - val_accuracy: 0.9177\n",
      "Epoch 32/50\n",
      "1500/1500 - 3s - loss: 0.2102 - accuracy: 0.9205 - val_loss: 0.2438 - val_accuracy: 0.9084\n",
      "Epoch 33/50\n",
      "1500/1500 - 3s - loss: 0.2110 - accuracy: 0.9194 - val_loss: 0.2393 - val_accuracy: 0.9130\n",
      "Epoch 34/50\n",
      "1500/1500 - 3s - loss: 0.2080 - accuracy: 0.9214 - val_loss: 0.2347 - val_accuracy: 0.9118\n",
      "Epoch 35/50\n",
      "1500/1500 - 3s - loss: 0.2063 - accuracy: 0.9211 - val_loss: 0.2320 - val_accuracy: 0.9136\n",
      "Epoch 36/50\n",
      "1500/1500 - 3s - loss: 0.2061 - accuracy: 0.9219 - val_loss: 0.2322 - val_accuracy: 0.9123\n",
      "Epoch 37/50\n",
      "1500/1500 - 3s - loss: 0.2065 - accuracy: 0.9215 - val_loss: 0.2294 - val_accuracy: 0.9142\n",
      "Epoch 38/50\n",
      "1500/1500 - 3s - loss: 0.2018 - accuracy: 0.9222 - val_loss: 0.2281 - val_accuracy: 0.9172\n",
      "Epoch 39/50\n",
      "1500/1500 - 3s - loss: 0.2025 - accuracy: 0.9229 - val_loss: 0.2362 - val_accuracy: 0.9133\n",
      "Epoch 40/50\n",
      "1500/1500 - 3s - loss: 0.2009 - accuracy: 0.9231 - val_loss: 0.2339 - val_accuracy: 0.9132\n",
      "Epoch 41/50\n",
      "1500/1500 - 3s - loss: 0.2007 - accuracy: 0.9241 - val_loss: 0.2377 - val_accuracy: 0.9116\n",
      "Epoch 42/50\n",
      "1500/1500 - 3s - loss: 0.2006 - accuracy: 0.9244 - val_loss: 0.2436 - val_accuracy: 0.9101\n",
      "Epoch 43/50\n",
      "1500/1500 - 3s - loss: 0.1981 - accuracy: 0.9241 - val_loss: 0.2325 - val_accuracy: 0.9128\n",
      "Epoch 44/50\n",
      "1500/1500 - 3s - loss: 0.1958 - accuracy: 0.9256 - val_loss: 0.2422 - val_accuracy: 0.9128\n",
      "Epoch 45/50\n",
      "1500/1500 - 3s - loss: 0.1953 - accuracy: 0.9240 - val_loss: 0.2348 - val_accuracy: 0.9138\n",
      "Epoch 46/50\n",
      "1500/1500 - 3s - loss: 0.1938 - accuracy: 0.9247 - val_loss: 0.2395 - val_accuracy: 0.9128\n",
      "Epoch 47/50\n",
      "1500/1500 - 3s - loss: 0.1926 - accuracy: 0.9259 - val_loss: 0.2363 - val_accuracy: 0.9155\n",
      "Epoch 48/50\n",
      "1500/1500 - 3s - loss: 0.1938 - accuracy: 0.9262 - val_loss: 0.2250 - val_accuracy: 0.9183\n",
      "Epoch 49/50\n",
      "1500/1500 - 3s - loss: 0.1915 - accuracy: 0.9269 - val_loss: 0.2358 - val_accuracy: 0.9122\n",
      "Epoch 50/50\n",
      "1500/1500 - 3s - loss: 0.1880 - accuracy: 0.9276 - val_loss: 0.2380 - val_accuracy: 0.9157\n",
      "Epoch 1/50\n",
      "1500/1500 - 3s - loss: 0.5116 - accuracy: 0.8119 - val_loss: 0.3668 - val_accuracy: 0.8656\n",
      "Epoch 2/50\n",
      "1500/1500 - 3s - loss: 0.3369 - accuracy: 0.8752 - val_loss: 0.3169 - val_accuracy: 0.8801\n",
      "Epoch 3/50\n",
      "1500/1500 - 3s - loss: 0.2955 - accuracy: 0.8901 - val_loss: 0.2732 - val_accuracy: 0.9000\n",
      "Epoch 4/50\n",
      "1500/1500 - 3s - loss: 0.2727 - accuracy: 0.8992 - val_loss: 0.2622 - val_accuracy: 0.9041\n",
      "Epoch 5/50\n",
      "1500/1500 - 3s - loss: 0.2537 - accuracy: 0.9046 - val_loss: 0.2473 - val_accuracy: 0.9093\n",
      "Epoch 6/50\n",
      "1500/1500 - 3s - loss: 0.2383 - accuracy: 0.9111 - val_loss: 0.2482 - val_accuracy: 0.9112\n",
      "Epoch 7/50\n",
      "1500/1500 - 3s - loss: 0.2276 - accuracy: 0.9150 - val_loss: 0.2312 - val_accuracy: 0.9144\n",
      "Epoch 8/50\n",
      "1500/1500 - 3s - loss: 0.2123 - accuracy: 0.9200 - val_loss: 0.2507 - val_accuracy: 0.9037\n",
      "Epoch 9/50\n",
      "1500/1500 - 3s - loss: 0.2047 - accuracy: 0.9233 - val_loss: 0.2314 - val_accuracy: 0.9131\n",
      "Epoch 10/50\n",
      "1500/1500 - 3s - loss: 0.1989 - accuracy: 0.9236 - val_loss: 0.2385 - val_accuracy: 0.9133\n",
      "Epoch 11/50\n",
      "1500/1500 - 3s - loss: 0.1867 - accuracy: 0.9294 - val_loss: 0.2389 - val_accuracy: 0.9160\n",
      "Epoch 12/50\n",
      "1500/1500 - 3s - loss: 0.1818 - accuracy: 0.9306 - val_loss: 0.2247 - val_accuracy: 0.9172\n",
      "Epoch 13/50\n",
      "1500/1500 - 3s - loss: 0.1768 - accuracy: 0.9317 - val_loss: 0.2230 - val_accuracy: 0.9202\n",
      "Epoch 14/50\n",
      "1500/1500 - 3s - loss: 0.1718 - accuracy: 0.9335 - val_loss: 0.2259 - val_accuracy: 0.9168\n",
      "Epoch 15/50\n",
      "1500/1500 - 3s - loss: 0.1631 - accuracy: 0.9370 - val_loss: 0.2365 - val_accuracy: 0.9174\n",
      "Epoch 16/50\n",
      "1500/1500 - 3s - loss: 0.1635 - accuracy: 0.9370 - val_loss: 0.2315 - val_accuracy: 0.9181\n",
      "Epoch 17/50\n",
      "1500/1500 - 3s - loss: 0.1581 - accuracy: 0.9397 - val_loss: 0.2211 - val_accuracy: 0.9207\n",
      "Epoch 18/50\n",
      "1500/1500 - 3s - loss: 0.1531 - accuracy: 0.9420 - val_loss: 0.2303 - val_accuracy: 0.9205\n",
      "Epoch 19/50\n",
      "1500/1500 - 3s - loss: 0.1498 - accuracy: 0.9425 - val_loss: 0.2568 - val_accuracy: 0.9083\n",
      "Epoch 20/50\n",
      "1500/1500 - 3s - loss: 0.1461 - accuracy: 0.9440 - val_loss: 0.2331 - val_accuracy: 0.9193\n",
      "Epoch 21/50\n",
      "1500/1500 - 3s - loss: 0.1427 - accuracy: 0.9462 - val_loss: 0.2305 - val_accuracy: 0.9202\n",
      "Epoch 22/50\n",
      "1500/1500 - 3s - loss: 0.1418 - accuracy: 0.9454 - val_loss: 0.2452 - val_accuracy: 0.9199\n",
      "Epoch 23/50\n",
      "1500/1500 - 3s - loss: 0.1343 - accuracy: 0.9483 - val_loss: 0.2438 - val_accuracy: 0.9153\n",
      "Epoch 24/50\n",
      "1500/1500 - 3s - loss: 0.1302 - accuracy: 0.9508 - val_loss: 0.2453 - val_accuracy: 0.9193\n",
      "Epoch 25/50\n",
      "1500/1500 - 3s - loss: 0.1269 - accuracy: 0.9510 - val_loss: 0.2500 - val_accuracy: 0.9217\n",
      "Epoch 26/50\n",
      "1500/1500 - 3s - loss: 0.1277 - accuracy: 0.9509 - val_loss: 0.2545 - val_accuracy: 0.9162\n",
      "Epoch 27/50\n",
      "1500/1500 - 3s - loss: 0.1254 - accuracy: 0.9521 - val_loss: 0.2630 - val_accuracy: 0.9197\n",
      "Epoch 28/50\n",
      "1500/1500 - 3s - loss: 0.1226 - accuracy: 0.9539 - val_loss: 0.2601 - val_accuracy: 0.9208\n",
      "Epoch 29/50\n",
      "1500/1500 - 3s - loss: 0.1234 - accuracy: 0.9538 - val_loss: 0.2624 - val_accuracy: 0.9194\n",
      "Epoch 30/50\n",
      "1500/1500 - 3s - loss: 0.1190 - accuracy: 0.9543 - val_loss: 0.2500 - val_accuracy: 0.9226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "1500/1500 - 3s - loss: 0.1168 - accuracy: 0.9561 - val_loss: 0.2495 - val_accuracy: 0.9192\n",
      "Epoch 32/50\n",
      "1500/1500 - 3s - loss: 0.1152 - accuracy: 0.9550 - val_loss: 0.2622 - val_accuracy: 0.9177\n",
      "Epoch 33/50\n",
      "1500/1500 - 3s - loss: 0.1138 - accuracy: 0.9571 - val_loss: 0.2662 - val_accuracy: 0.9215\n",
      "Epoch 34/50\n",
      "1500/1500 - 3s - loss: 0.1158 - accuracy: 0.9568 - val_loss: 0.2652 - val_accuracy: 0.9187\n",
      "Epoch 35/50\n",
      "1500/1500 - 3s - loss: 0.1062 - accuracy: 0.9582 - val_loss: 0.2673 - val_accuracy: 0.9237\n",
      "Epoch 36/50\n",
      "1500/1500 - 3s - loss: 0.1072 - accuracy: 0.9602 - val_loss: 0.2725 - val_accuracy: 0.9193\n",
      "Epoch 37/50\n",
      "1500/1500 - 3s - loss: 0.1092 - accuracy: 0.9595 - val_loss: 0.2755 - val_accuracy: 0.9187\n",
      "Epoch 38/50\n",
      "1500/1500 - 3s - loss: 0.1057 - accuracy: 0.9604 - val_loss: 0.2778 - val_accuracy: 0.9168\n",
      "Epoch 39/50\n",
      "1500/1500 - 3s - loss: 0.1034 - accuracy: 0.9623 - val_loss: 0.2782 - val_accuracy: 0.9212\n",
      "Epoch 40/50\n",
      "1500/1500 - 3s - loss: 0.1029 - accuracy: 0.9617 - val_loss: 0.2714 - val_accuracy: 0.9202\n",
      "Epoch 41/50\n",
      "1500/1500 - 3s - loss: 0.1002 - accuracy: 0.9622 - val_loss: 0.2952 - val_accuracy: 0.9197\n",
      "Epoch 42/50\n",
      "1500/1500 - 3s - loss: 0.1006 - accuracy: 0.9617 - val_loss: 0.2873 - val_accuracy: 0.9221\n",
      "Epoch 43/50\n",
      "1500/1500 - 3s - loss: 0.1006 - accuracy: 0.9625 - val_loss: 0.2840 - val_accuracy: 0.9185\n",
      "Epoch 44/50\n",
      "1500/1500 - 3s - loss: 0.0990 - accuracy: 0.9631 - val_loss: 0.2772 - val_accuracy: 0.9192\n",
      "Epoch 45/50\n",
      "1500/1500 - 3s - loss: 0.0977 - accuracy: 0.9637 - val_loss: 0.2826 - val_accuracy: 0.9220\n",
      "Epoch 46/50\n",
      "1500/1500 - 3s - loss: 0.0942 - accuracy: 0.9649 - val_loss: 0.2821 - val_accuracy: 0.9194\n",
      "Epoch 47/50\n",
      "1500/1500 - 3s - loss: 0.0949 - accuracy: 0.9647 - val_loss: 0.3099 - val_accuracy: 0.9222\n",
      "Epoch 48/50\n",
      "1500/1500 - 3s - loss: 0.0939 - accuracy: 0.9656 - val_loss: 0.2930 - val_accuracy: 0.9212\n",
      "Epoch 49/50\n",
      "1500/1500 - 3s - loss: 0.0949 - accuracy: 0.9654 - val_loss: 0.3006 - val_accuracy: 0.9184\n",
      "Epoch 50/50\n",
      "1500/1500 - 3s - loss: 0.0945 - accuracy: 0.9656 - val_loss: 0.2960 - val_accuracy: 0.9178\n",
      "Epoch 1/50\n",
      "1500/1500 - 5s - loss: 0.8004 - accuracy: 0.6923 - val_loss: 0.5153 - val_accuracy: 0.8141\n",
      "Epoch 2/50\n",
      "1500/1500 - 4s - loss: 0.5406 - accuracy: 0.7982 - val_loss: 0.4098 - val_accuracy: 0.8458\n",
      "Epoch 3/50\n",
      "1500/1500 - 4s - loss: 0.4730 - accuracy: 0.8240 - val_loss: 0.3708 - val_accuracy: 0.8610\n",
      "Epoch 4/50\n",
      "1500/1500 - 4s - loss: 0.4372 - accuracy: 0.8370 - val_loss: 0.3875 - val_accuracy: 0.8560\n",
      "Epoch 5/50\n",
      "1500/1500 - 4s - loss: 0.4153 - accuracy: 0.8463 - val_loss: 0.3445 - val_accuracy: 0.8698\n",
      "Epoch 6/50\n",
      "1500/1500 - 4s - loss: 0.3967 - accuracy: 0.8533 - val_loss: 0.3218 - val_accuracy: 0.8773\n",
      "Epoch 7/50\n",
      "1500/1500 - 4s - loss: 0.3870 - accuracy: 0.8567 - val_loss: 0.3116 - val_accuracy: 0.8813\n",
      "Epoch 8/50\n",
      "1500/1500 - 4s - loss: 0.3793 - accuracy: 0.8602 - val_loss: 0.3133 - val_accuracy: 0.8834\n",
      "Epoch 9/50\n",
      "1500/1500 - 4s - loss: 0.3709 - accuracy: 0.8614 - val_loss: 0.2994 - val_accuracy: 0.8894\n",
      "Epoch 10/50\n",
      "1500/1500 - 4s - loss: 0.3652 - accuracy: 0.8646 - val_loss: 0.3036 - val_accuracy: 0.8865\n",
      "Epoch 11/50\n",
      "1500/1500 - 4s - loss: 0.3581 - accuracy: 0.8670 - val_loss: 0.2861 - val_accuracy: 0.8953\n",
      "Epoch 12/50\n",
      "1500/1500 - 4s - loss: 0.3552 - accuracy: 0.8681 - val_loss: 0.2848 - val_accuracy: 0.8913\n",
      "Epoch 13/50\n",
      "1500/1500 - 4s - loss: 0.3509 - accuracy: 0.8718 - val_loss: 0.2816 - val_accuracy: 0.8978\n",
      "Epoch 14/50\n",
      "1500/1500 - 4s - loss: 0.3482 - accuracy: 0.8712 - val_loss: 0.2770 - val_accuracy: 0.8980\n",
      "Epoch 15/50\n",
      "1500/1500 - 4s - loss: 0.3432 - accuracy: 0.8739 - val_loss: 0.2776 - val_accuracy: 0.8976\n",
      "Epoch 16/50\n",
      "1500/1500 - 4s - loss: 0.3392 - accuracy: 0.8762 - val_loss: 0.2849 - val_accuracy: 0.8922\n",
      "Epoch 17/50\n",
      "1500/1500 - 4s - loss: 0.3353 - accuracy: 0.8759 - val_loss: 0.2699 - val_accuracy: 0.9011\n",
      "Epoch 18/50\n",
      "1500/1500 - 4s - loss: 0.3365 - accuracy: 0.8758 - val_loss: 0.2750 - val_accuracy: 0.9001\n",
      "Epoch 19/50\n",
      "1500/1500 - 4s - loss: 0.3307 - accuracy: 0.8762 - val_loss: 0.2705 - val_accuracy: 0.9017\n",
      "Epoch 20/50\n",
      "1500/1500 - 4s - loss: 0.3351 - accuracy: 0.8750 - val_loss: 0.2724 - val_accuracy: 0.8992\n",
      "Epoch 21/50\n",
      "1500/1500 - 4s - loss: 0.3298 - accuracy: 0.8775 - val_loss: 0.2702 - val_accuracy: 0.9013\n",
      "Epoch 22/50\n",
      "1500/1500 - 4s - loss: 0.3310 - accuracy: 0.8770 - val_loss: 0.2705 - val_accuracy: 0.8997\n",
      "Epoch 23/50\n",
      "1500/1500 - 4s - loss: 0.3242 - accuracy: 0.8782 - val_loss: 0.2620 - val_accuracy: 0.9043\n",
      "Epoch 24/50\n",
      "1500/1500 - 4s - loss: 0.3259 - accuracy: 0.8783 - val_loss: 0.2709 - val_accuracy: 0.8978\n",
      "Epoch 25/50\n",
      "1500/1500 - 4s - loss: 0.3194 - accuracy: 0.8815 - val_loss: 0.2626 - val_accuracy: 0.9043\n",
      "Epoch 26/50\n",
      "1500/1500 - 4s - loss: 0.3236 - accuracy: 0.8792 - val_loss: 0.2718 - val_accuracy: 0.8967\n",
      "Epoch 27/50\n",
      "1500/1500 - 4s - loss: 0.3159 - accuracy: 0.8831 - val_loss: 0.2674 - val_accuracy: 0.9018\n",
      "Epoch 28/50\n",
      "1500/1500 - 4s - loss: 0.3272 - accuracy: 0.8796 - val_loss: 0.2671 - val_accuracy: 0.9002\n",
      "Epoch 29/50\n",
      "1500/1500 - 4s - loss: 0.3181 - accuracy: 0.8814 - val_loss: 0.2687 - val_accuracy: 0.9034\n",
      "Epoch 30/50\n",
      "1500/1500 - 4s - loss: 0.3132 - accuracy: 0.8829 - val_loss: 0.2614 - val_accuracy: 0.9034\n",
      "Epoch 31/50\n",
      "1500/1500 - 4s - loss: 0.3175 - accuracy: 0.8825 - val_loss: 0.2567 - val_accuracy: 0.9066\n",
      "Epoch 32/50\n",
      "1500/1500 - 4s - loss: 0.3132 - accuracy: 0.8828 - val_loss: 0.2578 - val_accuracy: 0.9038\n",
      "Epoch 33/50\n",
      "1500/1500 - 4s - loss: 0.3140 - accuracy: 0.8829 - val_loss: 0.2559 - val_accuracy: 0.9064\n",
      "Epoch 34/50\n",
      "1500/1500 - 4s - loss: 0.3099 - accuracy: 0.8859 - val_loss: 0.2674 - val_accuracy: 0.9003\n",
      "Epoch 35/50\n",
      "1500/1500 - 4s - loss: 0.3122 - accuracy: 0.8829 - val_loss: 0.2529 - val_accuracy: 0.9120\n",
      "Epoch 36/50\n",
      "1500/1500 - 4s - loss: 0.3074 - accuracy: 0.8867 - val_loss: 0.2524 - val_accuracy: 0.9062\n",
      "Epoch 37/50\n",
      "1500/1500 - 4s - loss: 0.3060 - accuracy: 0.8871 - val_loss: 0.2570 - val_accuracy: 0.9047\n",
      "Epoch 38/50\n",
      "1500/1500 - 4s - loss: 0.3118 - accuracy: 0.8834 - val_loss: 0.2527 - val_accuracy: 0.9088\n",
      "Epoch 39/50\n",
      "1500/1500 - 4s - loss: 0.3113 - accuracy: 0.8841 - val_loss: 0.2573 - val_accuracy: 0.9066\n",
      "Epoch 40/50\n",
      "1500/1500 - 4s - loss: 0.3071 - accuracy: 0.8861 - val_loss: 0.2541 - val_accuracy: 0.9074\n",
      "Epoch 41/50\n",
      "1500/1500 - 4s - loss: 0.3048 - accuracy: 0.8874 - val_loss: 0.2458 - val_accuracy: 0.9099\n",
      "Epoch 42/50\n",
      "1500/1500 - 4s - loss: 0.3057 - accuracy: 0.8879 - val_loss: 0.2619 - val_accuracy: 0.9030\n",
      "Epoch 43/50\n",
      "1500/1500 - 4s - loss: 0.3016 - accuracy: 0.8883 - val_loss: 0.2547 - val_accuracy: 0.9077\n",
      "Epoch 44/50\n",
      "1500/1500 - 4s - loss: 0.3062 - accuracy: 0.8878 - val_loss: 0.2653 - val_accuracy: 0.9035\n",
      "Epoch 45/50\n",
      "1500/1500 - 4s - loss: 0.3043 - accuracy: 0.8857 - val_loss: 0.2460 - val_accuracy: 0.9097\n",
      "Epoch 46/50\n",
      "1500/1500 - 4s - loss: 0.3034 - accuracy: 0.8877 - val_loss: 0.2441 - val_accuracy: 0.9103\n",
      "Epoch 47/50\n",
      "1500/1500 - 4s - loss: 0.3018 - accuracy: 0.8904 - val_loss: 0.2543 - val_accuracy: 0.9061\n",
      "Epoch 48/50\n",
      "1500/1500 - 4s - loss: 0.2970 - accuracy: 0.8908 - val_loss: 0.2482 - val_accuracy: 0.9099\n",
      "Epoch 49/50\n",
      "1500/1500 - 4s - loss: 0.3014 - accuracy: 0.8882 - val_loss: 0.2436 - val_accuracy: 0.9103\n",
      "Epoch 50/50\n",
      "1500/1500 - 4s - loss: 0.3003 - accuracy: 0.8900 - val_loss: 0.2486 - val_accuracy: 0.9087\n",
      "Epoch 1/50\n",
      "1500/1500 - 4s - loss: 0.6727 - accuracy: 0.7417 - val_loss: 0.4547 - val_accuracy: 0.8275\n",
      "Epoch 2/50\n",
      "1500/1500 - 4s - loss: 0.4527 - accuracy: 0.8311 - val_loss: 0.3824 - val_accuracy: 0.8594\n",
      "Epoch 3/50\n",
      "1500/1500 - 4s - loss: 0.3976 - accuracy: 0.8518 - val_loss: 0.3285 - val_accuracy: 0.8782\n",
      "Epoch 4/50\n",
      "1500/1500 - 4s - loss: 0.3622 - accuracy: 0.8663 - val_loss: 0.3366 - val_accuracy: 0.8730\n",
      "Epoch 5/50\n",
      "1500/1500 - 3s - loss: 0.3451 - accuracy: 0.8713 - val_loss: 0.3146 - val_accuracy: 0.8825\n",
      "Epoch 6/50\n",
      "1500/1500 - 3s - loss: 0.3311 - accuracy: 0.8750 - val_loss: 0.3051 - val_accuracy: 0.8857\n",
      "Epoch 7/50\n",
      "1500/1500 - 3s - loss: 0.3176 - accuracy: 0.8806 - val_loss: 0.3214 - val_accuracy: 0.8816\n",
      "Epoch 8/50\n",
      "1500/1500 - 3s - loss: 0.3064 - accuracy: 0.8840 - val_loss: 0.3020 - val_accuracy: 0.8860\n",
      "Epoch 9/50\n",
      "1500/1500 - 3s - loss: 0.2957 - accuracy: 0.8880 - val_loss: 0.2826 - val_accuracy: 0.8939\n",
      "Epoch 10/50\n",
      "1500/1500 - 3s - loss: 0.2891 - accuracy: 0.8909 - val_loss: 0.2706 - val_accuracy: 0.9013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "1500/1500 - 3s - loss: 0.2843 - accuracy: 0.8930 - val_loss: 0.2656 - val_accuracy: 0.9024\n",
      "Epoch 12/50\n",
      "1500/1500 - 3s - loss: 0.2784 - accuracy: 0.8953 - val_loss: 0.2749 - val_accuracy: 0.8983\n",
      "Epoch 13/50\n",
      "1500/1500 - 3s - loss: 0.2733 - accuracy: 0.8987 - val_loss: 0.2578 - val_accuracy: 0.9067\n",
      "Epoch 14/50\n",
      "1500/1500 - 3s - loss: 0.2665 - accuracy: 0.8995 - val_loss: 0.2540 - val_accuracy: 0.9069\n",
      "Epoch 15/50\n",
      "1500/1500 - 3s - loss: 0.2638 - accuracy: 0.9007 - val_loss: 0.2691 - val_accuracy: 0.9030\n",
      "Epoch 16/50\n",
      "1500/1500 - 3s - loss: 0.2596 - accuracy: 0.9011 - val_loss: 0.2555 - val_accuracy: 0.9059\n",
      "Epoch 17/50\n",
      "1500/1500 - 3s - loss: 0.2568 - accuracy: 0.9039 - val_loss: 0.2728 - val_accuracy: 0.9008\n",
      "Epoch 18/50\n",
      "1500/1500 - 3s - loss: 0.2516 - accuracy: 0.9050 - val_loss: 0.2616 - val_accuracy: 0.9071\n",
      "Epoch 19/50\n",
      "1500/1500 - 3s - loss: 0.2513 - accuracy: 0.9053 - val_loss: 0.2573 - val_accuracy: 0.9066\n",
      "Epoch 20/50\n",
      "1500/1500 - 3s - loss: 0.2460 - accuracy: 0.9080 - val_loss: 0.2540 - val_accuracy: 0.9065\n",
      "Epoch 21/50\n",
      "1500/1500 - 4s - loss: 0.2450 - accuracy: 0.9074 - val_loss: 0.2432 - val_accuracy: 0.9113\n",
      "Epoch 22/50\n",
      "1500/1500 - 4s - loss: 0.2414 - accuracy: 0.9070 - val_loss: 0.2461 - val_accuracy: 0.9101\n",
      "Epoch 23/50\n",
      "1500/1500 - 4s - loss: 0.2401 - accuracy: 0.9093 - val_loss: 0.2495 - val_accuracy: 0.9113\n",
      "Epoch 24/50\n",
      "1500/1500 - 4s - loss: 0.2335 - accuracy: 0.9115 - val_loss: 0.2657 - val_accuracy: 0.9090\n",
      "Epoch 25/50\n",
      "1500/1500 - 4s - loss: 0.2341 - accuracy: 0.9118 - val_loss: 0.2630 - val_accuracy: 0.9075\n",
      "Epoch 26/50\n",
      "1500/1500 - 3s - loss: 0.2309 - accuracy: 0.9113 - val_loss: 0.2543 - val_accuracy: 0.9067\n",
      "Epoch 27/50\n",
      "1500/1500 - 4s - loss: 0.2274 - accuracy: 0.9129 - val_loss: 0.2508 - val_accuracy: 0.9101\n",
      "Epoch 28/50\n",
      "1500/1500 - 3s - loss: 0.2274 - accuracy: 0.9125 - val_loss: 0.2655 - val_accuracy: 0.9051\n",
      "Epoch 29/50\n",
      "1500/1500 - 4s - loss: 0.2271 - accuracy: 0.9133 - val_loss: 0.2589 - val_accuracy: 0.9097\n",
      "Epoch 30/50\n",
      "1500/1500 - 3s - loss: 0.2223 - accuracy: 0.9146 - val_loss: 0.2579 - val_accuracy: 0.9078\n",
      "Epoch 31/50\n",
      "1500/1500 - 3s - loss: 0.2230 - accuracy: 0.9161 - val_loss: 0.2460 - val_accuracy: 0.9099\n",
      "Epoch 32/50\n",
      "1500/1500 - 3s - loss: 0.2204 - accuracy: 0.9161 - val_loss: 0.2578 - val_accuracy: 0.9068\n",
      "Epoch 33/50\n",
      "1500/1500 - 3s - loss: 0.2198 - accuracy: 0.9162 - val_loss: 0.2493 - val_accuracy: 0.9108\n",
      "Epoch 34/50\n",
      "1500/1500 - 3s - loss: 0.2182 - accuracy: 0.9164 - val_loss: 0.2509 - val_accuracy: 0.9090\n",
      "Epoch 35/50\n",
      "1500/1500 - 3s - loss: 0.2187 - accuracy: 0.9169 - val_loss: 0.2482 - val_accuracy: 0.9114\n",
      "Epoch 36/50\n",
      "1500/1500 - 4s - loss: 0.2129 - accuracy: 0.9175 - val_loss: 0.2596 - val_accuracy: 0.9105\n",
      "Epoch 37/50\n",
      "1500/1500 - 4s - loss: 0.2152 - accuracy: 0.9185 - val_loss: 0.2654 - val_accuracy: 0.9040\n",
      "Epoch 38/50\n",
      "1500/1500 - 4s - loss: 0.2136 - accuracy: 0.9182 - val_loss: 0.2468 - val_accuracy: 0.9114\n",
      "Epoch 39/50\n",
      "1500/1500 - 3s - loss: 0.2082 - accuracy: 0.9200 - val_loss: 0.2548 - val_accuracy: 0.9122\n",
      "Epoch 40/50\n",
      "1500/1500 - 3s - loss: 0.2105 - accuracy: 0.9202 - val_loss: 0.2599 - val_accuracy: 0.9093\n",
      "Epoch 41/50\n",
      "1500/1500 - 4s - loss: 0.2116 - accuracy: 0.9202 - val_loss: 0.2631 - val_accuracy: 0.9087\n",
      "Epoch 42/50\n",
      "1500/1500 - 3s - loss: 0.2090 - accuracy: 0.9194 - val_loss: 0.2510 - val_accuracy: 0.9100\n",
      "Epoch 43/50\n",
      "1500/1500 - 3s - loss: 0.2080 - accuracy: 0.9209 - val_loss: 0.2563 - val_accuracy: 0.9089\n",
      "Epoch 44/50\n",
      "1500/1500 - 3s - loss: 0.2036 - accuracy: 0.9225 - val_loss: 0.2534 - val_accuracy: 0.9120\n",
      "Epoch 45/50\n",
      "1500/1500 - 3s - loss: 0.2034 - accuracy: 0.9232 - val_loss: 0.2671 - val_accuracy: 0.9102\n",
      "Epoch 46/50\n",
      "1500/1500 - 3s - loss: 0.2052 - accuracy: 0.9222 - val_loss: 0.2592 - val_accuracy: 0.9109\n",
      "Epoch 47/50\n",
      "1500/1500 - 3s - loss: 0.2033 - accuracy: 0.9218 - val_loss: 0.2550 - val_accuracy: 0.9116\n",
      "Epoch 48/50\n",
      "1500/1500 - 3s - loss: 0.2023 - accuracy: 0.9229 - val_loss: 0.2539 - val_accuracy: 0.9121\n",
      "Epoch 49/50\n",
      "1500/1500 - 3s - loss: 0.2001 - accuracy: 0.9235 - val_loss: 0.2478 - val_accuracy: 0.9109\n",
      "Epoch 50/50\n",
      "1500/1500 - 3s - loss: 0.1997 - accuracy: 0.9241 - val_loss: 0.2521 - val_accuracy: 0.9125\n",
      "Epoch 1/50\n",
      "1500/1500 - 3s - loss: 0.6331 - accuracy: 0.7623 - val_loss: 0.4413 - val_accuracy: 0.8394\n",
      "Epoch 2/50\n",
      "1500/1500 - 3s - loss: 0.4435 - accuracy: 0.8367 - val_loss: 0.3674 - val_accuracy: 0.8642\n",
      "Epoch 3/50\n",
      "1500/1500 - 3s - loss: 0.3948 - accuracy: 0.8521 - val_loss: 0.3309 - val_accuracy: 0.8803\n",
      "Epoch 4/50\n",
      "1500/1500 - 3s - loss: 0.3654 - accuracy: 0.8658 - val_loss: 0.3247 - val_accuracy: 0.8800\n",
      "Epoch 5/50\n",
      "1500/1500 - 3s - loss: 0.3460 - accuracy: 0.8714 - val_loss: 0.3006 - val_accuracy: 0.8878\n",
      "Epoch 6/50\n",
      "1500/1500 - 3s - loss: 0.3345 - accuracy: 0.8753 - val_loss: 0.2930 - val_accuracy: 0.8917\n",
      "Epoch 7/50\n",
      "1500/1500 - 3s - loss: 0.3208 - accuracy: 0.8802 - val_loss: 0.2813 - val_accuracy: 0.8957\n",
      "Epoch 8/50\n",
      "1500/1500 - 3s - loss: 0.3128 - accuracy: 0.8825 - val_loss: 0.2955 - val_accuracy: 0.8921\n",
      "Epoch 9/50\n",
      "1500/1500 - 3s - loss: 0.3051 - accuracy: 0.8847 - val_loss: 0.2912 - val_accuracy: 0.8896\n",
      "Epoch 10/50\n",
      "1500/1500 - 3s - loss: 0.3028 - accuracy: 0.8865 - val_loss: 0.2767 - val_accuracy: 0.8987\n",
      "Epoch 11/50\n",
      "1500/1500 - 3s - loss: 0.2929 - accuracy: 0.8904 - val_loss: 0.2702 - val_accuracy: 0.8990\n",
      "Epoch 12/50\n",
      "1500/1500 - 3s - loss: 0.2879 - accuracy: 0.8907 - val_loss: 0.2704 - val_accuracy: 0.8979\n",
      "Epoch 13/50\n",
      "1500/1500 - 3s - loss: 0.2837 - accuracy: 0.8939 - val_loss: 0.2655 - val_accuracy: 0.8997\n",
      "Epoch 14/50\n",
      "1500/1500 - 3s - loss: 0.2795 - accuracy: 0.8944 - val_loss: 0.2620 - val_accuracy: 0.9021\n",
      "Epoch 15/50\n",
      "1500/1500 - 3s - loss: 0.2755 - accuracy: 0.8961 - val_loss: 0.2594 - val_accuracy: 0.9061\n",
      "Epoch 16/50\n",
      "1500/1500 - 3s - loss: 0.2717 - accuracy: 0.8983 - val_loss: 0.2611 - val_accuracy: 0.9041\n",
      "Epoch 17/50\n",
      "1500/1500 - 3s - loss: 0.2724 - accuracy: 0.8974 - val_loss: 0.2647 - val_accuracy: 0.9027\n",
      "Epoch 18/50\n",
      "1500/1500 - 3s - loss: 0.2680 - accuracy: 0.8985 - val_loss: 0.2663 - val_accuracy: 0.9022\n",
      "Epoch 19/50\n",
      "1500/1500 - 3s - loss: 0.2639 - accuracy: 0.9003 - val_loss: 0.2633 - val_accuracy: 0.9037\n",
      "Epoch 20/50\n",
      "1500/1500 - 3s - loss: 0.2613 - accuracy: 0.9008 - val_loss: 0.2574 - val_accuracy: 0.9051\n",
      "Epoch 21/50\n",
      "1500/1500 - 3s - loss: 0.2569 - accuracy: 0.9024 - val_loss: 0.2520 - val_accuracy: 0.9083\n",
      "Epoch 22/50\n",
      "1500/1500 - 3s - loss: 0.2538 - accuracy: 0.9036 - val_loss: 0.2524 - val_accuracy: 0.9096\n",
      "Epoch 23/50\n",
      "1500/1500 - 3s - loss: 0.2539 - accuracy: 0.9055 - val_loss: 0.2611 - val_accuracy: 0.9057\n",
      "Epoch 24/50\n",
      "1500/1500 - 3s - loss: 0.2515 - accuracy: 0.9048 - val_loss: 0.2592 - val_accuracy: 0.9044\n",
      "Epoch 25/50\n",
      "1500/1500 - 3s - loss: 0.2486 - accuracy: 0.9061 - val_loss: 0.2653 - val_accuracy: 0.9024\n",
      "Epoch 26/50\n",
      "1500/1500 - 3s - loss: 0.2497 - accuracy: 0.9038 - val_loss: 0.2620 - val_accuracy: 0.9013\n",
      "Epoch 27/50\n",
      "1500/1500 - 3s - loss: 0.2474 - accuracy: 0.9059 - val_loss: 0.2552 - val_accuracy: 0.9064\n",
      "Epoch 28/50\n",
      "1500/1500 - 3s - loss: 0.2438 - accuracy: 0.9074 - val_loss: 0.2513 - val_accuracy: 0.9088\n",
      "Epoch 29/50\n",
      "1500/1500 - 3s - loss: 0.2440 - accuracy: 0.9073 - val_loss: 0.2561 - val_accuracy: 0.9065\n",
      "Epoch 30/50\n",
      "1500/1500 - 3s - loss: 0.2404 - accuracy: 0.9079 - val_loss: 0.2539 - val_accuracy: 0.9070\n",
      "Epoch 31/50\n",
      "1500/1500 - 3s - loss: 0.2420 - accuracy: 0.9095 - val_loss: 0.2510 - val_accuracy: 0.9106\n",
      "Epoch 32/50\n",
      "1500/1500 - 3s - loss: 0.2403 - accuracy: 0.9092 - val_loss: 0.2481 - val_accuracy: 0.9097\n",
      "Epoch 33/50\n",
      "1500/1500 - 3s - loss: 0.2363 - accuracy: 0.9094 - val_loss: 0.2463 - val_accuracy: 0.9119\n",
      "Epoch 34/50\n",
      "1500/1500 - 3s - loss: 0.2383 - accuracy: 0.9096 - val_loss: 0.2558 - val_accuracy: 0.9056\n",
      "Epoch 35/50\n",
      "1500/1500 - 3s - loss: 0.2360 - accuracy: 0.9100 - val_loss: 0.2496 - val_accuracy: 0.9109\n",
      "Epoch 36/50\n",
      "1500/1500 - 3s - loss: 0.2348 - accuracy: 0.9114 - val_loss: 0.2505 - val_accuracy: 0.9112\n",
      "Epoch 37/50\n",
      "1500/1500 - 3s - loss: 0.2329 - accuracy: 0.9107 - val_loss: 0.2580 - val_accuracy: 0.9074\n",
      "Epoch 38/50\n",
      "1500/1500 - 3s - loss: 0.2325 - accuracy: 0.9111 - val_loss: 0.2541 - val_accuracy: 0.9079\n",
      "Epoch 39/50\n",
      "1500/1500 - 3s - loss: 0.2335 - accuracy: 0.9120 - val_loss: 0.2527 - val_accuracy: 0.9097\n",
      "Epoch 40/50\n",
      "1500/1500 - 3s - loss: 0.2284 - accuracy: 0.9141 - val_loss: 0.2448 - val_accuracy: 0.9103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "1500/1500 - 3s - loss: 0.2261 - accuracy: 0.9128 - val_loss: 0.2627 - val_accuracy: 0.9099\n",
      "Epoch 42/50\n",
      "1500/1500 - 3s - loss: 0.2309 - accuracy: 0.9116 - val_loss: 0.2456 - val_accuracy: 0.9135\n",
      "Epoch 43/50\n",
      "1500/1500 - 3s - loss: 0.2237 - accuracy: 0.9159 - val_loss: 0.2535 - val_accuracy: 0.9096\n",
      "Epoch 44/50\n",
      "1500/1500 - 3s - loss: 0.2263 - accuracy: 0.9132 - val_loss: 0.2558 - val_accuracy: 0.9104\n",
      "Epoch 45/50\n",
      "1500/1500 - 3s - loss: 0.2246 - accuracy: 0.9149 - val_loss: 0.2545 - val_accuracy: 0.9068\n",
      "Epoch 46/50\n",
      "1500/1500 - 3s - loss: 0.2250 - accuracy: 0.9139 - val_loss: 0.2672 - val_accuracy: 0.9043\n",
      "Epoch 47/50\n",
      "1500/1500 - 3s - loss: 0.2259 - accuracy: 0.9134 - val_loss: 0.2479 - val_accuracy: 0.9105\n",
      "Epoch 48/50\n",
      "1500/1500 - 3s - loss: 0.2218 - accuracy: 0.9144 - val_loss: 0.2552 - val_accuracy: 0.9128\n",
      "Epoch 49/50\n",
      "1500/1500 - 3s - loss: 0.2225 - accuracy: 0.9149 - val_loss: 0.2562 - val_accuracy: 0.9089\n",
      "Epoch 50/50\n",
      "1500/1500 - 3s - loss: 0.2221 - accuracy: 0.9138 - val_loss: 0.2539 - val_accuracy: 0.9101\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "modelp3_1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 1.\n",
    "train_hist = modelp3_1.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 2)\n",
    "\n",
    "#2\n",
    "modelp3_2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 2.\n",
    "train_hist = modelp3_2.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 2)\n",
    "\n",
    "#3\n",
    "modelp3_3.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 3.\n",
    "train_hist = modelp3_3.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 2)\n",
    "\n",
    "#4\n",
    "modelp3_4.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 4.\n",
    "train_hist = modelp3_4.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 2)\n",
    "\n",
    "#5\n",
    "modelp3_5.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 5.\n",
    "train_hist = modelp3_5.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9023759f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 6)         60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 12, 12, 16)        880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 81,194\n",
      "Trainable params: 81,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 - 0s - loss: 0.2518 - accuracy: 0.9126\n",
      "\n",
      "Test accuracy: 0.9125999808311462\n",
      "FLOPS: 507814\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 10, 10, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 265,930\n",
      "Trainable params: 265,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 - 1s - loss: 0.3242 - accuracy: 0.9189\n",
      "\n",
      "Test accuracy: 0.9189000129699707\n",
      "FLOPS: 11984842\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 14, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 7, 7, 32)          12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 3, 3, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 120)               7800      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 85,482\n",
      "Trainable params: 85,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 - 1s - loss: 0.2634 - accuracy: 0.9037\n",
      "\n",
      "Test accuracy: 0.9036999940872192\n",
      "FLOPS: 3408646\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 12, 12, 16)        880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 110,330\n",
      "Trainable params: 110,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.2669 - accuracy: 0.9097\n",
      "\n",
      "Test accuracy: 0.9096999764442444\n",
      "FLOPS: 716182\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 - 0s - loss: 0.2694 - accuracy: 0.9055\n",
      "\n",
      "Test accuracy: 0.9054999947547913\n",
      "FLOPS: 845862\n"
     ]
    }
   ],
   "source": [
    "modelp3_1.summary()\n",
    "test_loss, test_acc = modelp3_1.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(modelp3_1, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")\n",
    "\n",
    "modelp3_2.summary()\n",
    "test_loss, test_acc = modelp3_2.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(modelp3_2, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")\n",
    "\n",
    "modelp3_3.summary()\n",
    "test_loss, test_acc = modelp3_3.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(modelp3_3, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")\n",
    "\n",
    "modelp3_4.summary()\n",
    "test_loss, test_acc = modelp3_4.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(modelp3_4, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")\n",
    "\n",
    "modelp3_5.summary()\n",
    "test_loss, test_acc = modelp3_5.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(modelp3_5, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358f75f",
   "metadata": {},
   "source": [
    "Problem 4 (30 pts)\n",
    "\n",
    "AlexNet may be too complex for the Fashion-MNIST dataset, in particular, due to the low resolution of the initial images; try simplifying the model to make the training faster while ensuring that the accuracy stays relatively high. Compare your training loss, training, and validation accuracy against the best model in Problem 3 and Problem 2. Also, measure your computational saving in the number of operations as well as the number of parameters in your network using ptflops https://pypi.org/project/ptflops/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "730ea5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard AlexNet\n",
    "\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(96, kernel_size=(11,11), strides=(4,4), padding='same', activation = 'relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size = (3,3), strides=(2,2))(x)\n",
    "x = layers.Conv2D(256, kernel_size=(5,5), padding='same', activation = 'relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size = (3,3), strides=(2,2))(x)\n",
    "x = layers.Conv2D(384, kernel_size=(3,3), padding='same', activation = 'relu')(inputs)\n",
    "x = layers.Conv2D(384, kernel_size=(3,3), padding='same', activation = 'relu')(inputs)\n",
    "x = layers.Conv2D(256, kernel_size=(3,3), padding='same', activation = 'relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size = (3,3), strides=(2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(4096, activation='relu')(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Dense(4096, activation='relu')(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "outputs = layers.Dense(10)(x) \n",
    "AlexNet = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba156f6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 - 34s - loss: 0.4150 - accuracy: 0.8572 - val_loss: 0.3287 - val_accuracy: 0.8855\n",
      "Epoch 2/50\n",
      "1500/1500 - 34s - loss: 0.2709 - accuracy: 0.9015 - val_loss: 0.2611 - val_accuracy: 0.9027\n",
      "Epoch 3/50\n",
      "1500/1500 - 34s - loss: 0.2221 - accuracy: 0.9164 - val_loss: 0.2773 - val_accuracy: 0.9082\n",
      "Epoch 4/50\n",
      "1500/1500 - 34s - loss: 0.1904 - accuracy: 0.9287 - val_loss: 0.2723 - val_accuracy: 0.9063\n",
      "Epoch 5/50\n",
      "1500/1500 - 34s - loss: 0.1608 - accuracy: 0.9397 - val_loss: 0.2887 - val_accuracy: 0.9095\n",
      "Epoch 6/50\n",
      "1500/1500 - 34s - loss: 0.1399 - accuracy: 0.9475 - val_loss: 0.3574 - val_accuracy: 0.9051\n",
      "Epoch 7/50\n",
      "1500/1500 - 34s - loss: 0.1272 - accuracy: 0.9533 - val_loss: 0.3416 - val_accuracy: 0.9128\n",
      "Epoch 8/50\n",
      "1500/1500 - 35s - loss: 0.1128 - accuracy: 0.9589 - val_loss: 0.3785 - val_accuracy: 0.9125\n",
      "Epoch 9/50\n",
      "1500/1500 - 35s - loss: 0.1040 - accuracy: 0.9628 - val_loss: 0.4172 - val_accuracy: 0.9072\n",
      "Epoch 10/50\n",
      "1500/1500 - 34s - loss: 0.0879 - accuracy: 0.9688 - val_loss: 0.4731 - val_accuracy: 0.9107\n",
      "Epoch 11/50\n",
      "1500/1500 - 34s - loss: 0.0815 - accuracy: 0.9724 - val_loss: 0.5062 - val_accuracy: 0.9106\n",
      "Epoch 12/50\n",
      "1500/1500 - 34s - loss: 0.0783 - accuracy: 0.9737 - val_loss: 0.4518 - val_accuracy: 0.9143\n",
      "Epoch 13/50\n",
      "1500/1500 - 34s - loss: 0.0769 - accuracy: 0.9744 - val_loss: 0.5785 - val_accuracy: 0.9056\n",
      "Epoch 14/50\n",
      "1500/1500 - 35s - loss: 0.0700 - accuracy: 0.9776 - val_loss: 0.5037 - val_accuracy: 0.9122\n",
      "Epoch 15/50\n",
      "1500/1500 - 34s - loss: 0.0599 - accuracy: 0.9798 - val_loss: 0.5751 - val_accuracy: 0.9096\n",
      "Epoch 16/50\n",
      "1500/1500 - 35s - loss: 0.0615 - accuracy: 0.9805 - val_loss: 0.6200 - val_accuracy: 0.9099\n",
      "Epoch 17/50\n",
      "1500/1500 - 34s - loss: 0.0585 - accuracy: 0.9809 - val_loss: 0.5815 - val_accuracy: 0.9120\n",
      "Epoch 18/50\n",
      "1500/1500 - 34s - loss: 0.0556 - accuracy: 0.9823 - val_loss: 0.6166 - val_accuracy: 0.9118\n",
      "Epoch 19/50\n",
      "1500/1500 - 35s - loss: 0.0601 - accuracy: 0.9827 - val_loss: 0.6933 - val_accuracy: 0.9066\n",
      "Epoch 20/50\n",
      "1500/1500 - 36s - loss: 0.0532 - accuracy: 0.9842 - val_loss: 0.6026 - val_accuracy: 0.9134\n",
      "Epoch 21/50\n",
      "1500/1500 - 34s - loss: 0.0473 - accuracy: 0.9864 - val_loss: 0.6397 - val_accuracy: 0.9159\n",
      "Epoch 22/50\n",
      "1500/1500 - 34s - loss: 0.0462 - accuracy: 0.9869 - val_loss: 0.7564 - val_accuracy: 0.9113\n",
      "Epoch 23/50\n",
      "1500/1500 - 34s - loss: 0.0496 - accuracy: 0.9853 - val_loss: 0.6897 - val_accuracy: 0.9168\n",
      "Epoch 24/50\n",
      "1500/1500 - 34s - loss: 0.0466 - accuracy: 0.9867 - val_loss: 0.8798 - val_accuracy: 0.9126\n",
      "Epoch 25/50\n",
      "1500/1500 - 35s - loss: 0.0410 - accuracy: 0.9886 - val_loss: 0.8531 - val_accuracy: 0.9102\n",
      "Epoch 26/50\n",
      "1500/1500 - 34s - loss: 0.0426 - accuracy: 0.9877 - val_loss: 0.8873 - val_accuracy: 0.9113\n",
      "Epoch 27/50\n",
      "1500/1500 - 34s - loss: 0.0471 - accuracy: 0.9874 - val_loss: 0.7806 - val_accuracy: 0.9144\n",
      "Epoch 28/50\n",
      "1500/1500 - 34s - loss: 0.0547 - accuracy: 0.9877 - val_loss: 0.7827 - val_accuracy: 0.9144\n",
      "Epoch 29/50\n",
      "1500/1500 - 34s - loss: 0.0361 - accuracy: 0.9898 - val_loss: 0.8831 - val_accuracy: 0.9118\n",
      "Epoch 30/50\n",
      "1500/1500 - 34s - loss: 0.0375 - accuracy: 0.9895 - val_loss: 1.0049 - val_accuracy: 0.9059\n",
      "Epoch 31/50\n",
      "1500/1500 - 35s - loss: 0.0449 - accuracy: 0.9887 - val_loss: 0.8515 - val_accuracy: 0.9119\n",
      "Epoch 32/50\n",
      "1500/1500 - 34s - loss: 0.0434 - accuracy: 0.9902 - val_loss: 0.8843 - val_accuracy: 0.9158\n",
      "Epoch 33/50\n",
      "1500/1500 - 34s - loss: 0.0377 - accuracy: 0.9901 - val_loss: 1.2164 - val_accuracy: 0.9059\n",
      "Epoch 34/50\n",
      "1500/1500 - 34s - loss: 0.0474 - accuracy: 0.9886 - val_loss: 0.8826 - val_accuracy: 0.9160\n",
      "Epoch 35/50\n",
      "1500/1500 - 35s - loss: 0.0324 - accuracy: 0.9914 - val_loss: 1.0393 - val_accuracy: 0.9137\n",
      "Epoch 36/50\n",
      "1500/1500 - 34s - loss: 0.0428 - accuracy: 0.9899 - val_loss: 1.0380 - val_accuracy: 0.9106\n",
      "Epoch 37/50\n",
      "1500/1500 - 34s - loss: 0.0419 - accuracy: 0.9900 - val_loss: 1.0204 - val_accuracy: 0.9118\n",
      "Epoch 38/50\n",
      "1500/1500 - 34s - loss: 0.0353 - accuracy: 0.9915 - val_loss: 1.0287 - val_accuracy: 0.9088\n",
      "Epoch 39/50\n",
      "1500/1500 - 34s - loss: 0.0361 - accuracy: 0.9909 - val_loss: 1.0773 - val_accuracy: 0.9099\n",
      "Epoch 40/50\n",
      "1500/1500 - 34s - loss: 0.0412 - accuracy: 0.9909 - val_loss: 1.0237 - val_accuracy: 0.9078\n",
      "Epoch 41/50\n",
      "1500/1500 - 34s - loss: 0.0349 - accuracy: 0.9919 - val_loss: 1.0741 - val_accuracy: 0.9128\n",
      "Epoch 42/50\n",
      "1500/1500 - 36s - loss: 0.0401 - accuracy: 0.9910 - val_loss: 1.2226 - val_accuracy: 0.9112\n",
      "Epoch 43/50\n",
      "1500/1500 - 35s - loss: 0.0295 - accuracy: 0.9923 - val_loss: 1.3183 - val_accuracy: 0.9143\n",
      "Epoch 44/50\n",
      "1500/1500 - 35s - loss: 0.0489 - accuracy: 0.9905 - val_loss: 1.1796 - val_accuracy: 0.9153\n",
      "Epoch 45/50\n",
      "1500/1500 - 34s - loss: 0.0288 - accuracy: 0.9929 - val_loss: 1.1328 - val_accuracy: 0.9105\n",
      "Epoch 46/50\n",
      "1500/1500 - 34s - loss: 0.0336 - accuracy: 0.9917 - val_loss: 1.4586 - val_accuracy: 0.9111\n",
      "Epoch 47/50\n",
      "1500/1500 - 34s - loss: 0.0368 - accuracy: 0.9920 - val_loss: 1.1803 - val_accuracy: 0.9113\n",
      "Epoch 48/50\n",
      "1500/1500 - 35s - loss: 0.0409 - accuracy: 0.9919 - val_loss: 1.2658 - val_accuracy: 0.9119\n",
      "Epoch 49/50\n",
      "1500/1500 - 34s - loss: 0.0282 - accuracy: 0.9934 - val_loss: 1.2394 - val_accuracy: 0.9133\n",
      "Epoch 50/50\n",
      "1500/1500 - 34s - loss: 0.0288 - accuracy: 0.9933 - val_loss: 1.3454 - val_accuracy: 0.9072\n"
     ]
    }
   ],
   "source": [
    "AlexNet.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 5.\n",
    "train_hist = AlexNet.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc6f401b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 28, 28, 256)       2560      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 4096)              177213440 \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 194,038,282\n",
      "Trainable params: 194,038,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 - 1s - loss: 1.4159 - accuracy: 0.9056\n",
      "\n",
      "Test accuracy: 0.9056000113487244\n",
      "FLOPS: 392265994\n"
     ]
    }
   ],
   "source": [
    "AlexNet.summary()\n",
    "test_loss, test_acc = AlexNet.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(AlexNet, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90a11dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet.save('AlexNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35ef3ffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[43264,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m AlexNet \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAlexNet.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py:201\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m load_context\u001b[38;5;241m.\u001b[39mload_context(options):\n\u001b[0;32m    199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    200\u001b[0m       (\u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile) \u001b[38;5;129;01mor\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mis_hdf5(filepath))):\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhdf5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m   filepath \u001b[38;5;241m=\u001b[39m path_to_string(filepath)\n\u001b[0;32m    205\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py:180\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    178\u001b[0m   model_config \u001b[38;5;241m=\u001b[39m model_config\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    179\u001b[0m model_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(model_config)\n\u001b[1;32m--> 180\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_config_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# set weights\u001b[39;00m\n\u001b[0;32m    184\u001b[0m load_weights_from_hdf5_group(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m'\u001b[39m], model\u001b[38;5;241m.\u001b[39mlayers)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\model_config.py:52\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     48\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`model_from_config` expects a dictionary, not a list. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     49\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaybe you meant to use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     50\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Sequential.from_config(config)`?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py:163\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03m\"\"\"Instantiates a layer from a config dictionary.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Layer instance (may be Model, Sequential, Network, Layer...)\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    162\u001b[0m populate_deserializable_objects()\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneric_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:674\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    671\u001b[0m custom_objects \u001b[38;5;241m=\u001b[39m custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom_objects\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec\u001b[38;5;241m.\u001b[39margs:\n\u001b[1;32m--> 674\u001b[0m   deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_GLOBAL_CUSTOM_OBJECTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    678\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    680\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m CustomObjectScope(custom_objects):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:668\u001b[0m, in \u001b[0;36mFunctional.from_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;124;03m\"\"\"Instantiates a Model from its config (output of `get_config()`).\u001b[39;00m\n\u001b[0;32m    654\u001b[0m \n\u001b[0;32m    655\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m    ValueError: In case of improperly formatted config dict.\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m generic_utils\u001b[38;5;241m.\u001b[39mSharedObjectLoadingScope():\n\u001b[1;32m--> 668\u001b[0m   input_tensors, output_tensors, created_layers \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruct_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    670\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(inputs\u001b[38;5;241m=\u001b[39minput_tensors, outputs\u001b[38;5;241m=\u001b[39moutput_tensors,\n\u001b[0;32m    671\u001b[0m               name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    672\u001b[0m   connect_ancillary_layers(model, created_layers)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:1289\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[1;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[0;32m   1287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m unprocessed_nodes:\n\u001b[0;32m   1288\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m node_data \u001b[38;5;129;01min\u001b[39;00m unprocessed_nodes\u001b[38;5;241m.\u001b[39mpop(layer):\n\u001b[1;32m-> 1289\u001b[0m         \u001b[43mprocess_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m input_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1292\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:1237\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[1;34m(layer, node_data)\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m layer\u001b[38;5;241m.\u001b[39m_preserve_input_structure_in_config:\n\u001b[0;32m   1235\u001b[0m   input_tensors \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1236\u001b[0m       base_layer_utils\u001b[38;5;241m.\u001b[39munnest_if_single_tensor(input_tensors))\n\u001b[1;32m-> 1237\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m layer(input_tensors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;66;03m# Update node index map.\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m output_index \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(output_tensors)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_keras_history\u001b[38;5;241m.\u001b[39mnode_index\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:996\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;66;03m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _in_functional_construction_mode(\u001b[38;5;28mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[1;32m--> 996\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_construction_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m call_context \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1134\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     training_arg_passed_by_framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[0;32m   1132\u001b[0m     layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39mtraining_value):\n\u001b[0;32m   1133\u001b[0m   \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[1;32m-> 1134\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_tensor_symbolic_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1137\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA layer\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms `call` method should return a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1139\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor or a list of Tensors, not None \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1140\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:867\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mmap_structure(keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor, output_signature)\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_output_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:905\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_scope()):  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    900\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m    901\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;66;03m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;66;03m# overridden).\u001b[39;00m\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;66;03m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[39;00m\n\u001b[1;32m--> 905\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[0;32m    907\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2667\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_default\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   2663\u001b[0m   \u001b[38;5;66;03m# Any setup work performed only once should happen in an `init_scope`\u001b[39;00m\n\u001b[0;32m   2664\u001b[0m   \u001b[38;5;66;03m# to avoid creating symbolic Tensors that will later pollute any eager\u001b[39;00m\n\u001b[0;32m   2665\u001b[0m   \u001b[38;5;66;03m# operations.\u001b[39;00m\n\u001b[0;32m   2666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf_utils\u001b[38;5;241m.\u001b[39mmaybe_init_scope(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 2667\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shapes\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint:disable=not-callable\u001b[39;00m\n\u001b[0;32m   2668\u001b[0m \u001b[38;5;66;03m# We must set also ensure that the layer is marked as built, and the build\u001b[39;00m\n\u001b[0;32m   2669\u001b[0m \u001b[38;5;66;03m# shape is stored since user defined build functions may not be calling\u001b[39;00m\n\u001b[0;32m   2670\u001b[0m \u001b[38;5;66;03m# `super.build()`\u001b[39;00m\n\u001b[0;32m   2671\u001b[0m Layer\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m, input_shapes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:1200\u001b[0m, in \u001b[0;36mDense.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m   1197\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe last dimension of the inputs to `Dense` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1198\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould be defined. Found `None`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m InputSpec(min_ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m: last_dim})\n\u001b[1;32m-> 1200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkernel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlast_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munits\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[0;32m   1209\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[0;32m   1210\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1211\u001b[0m       shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits,],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1215\u001b[0m       dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1216\u001b[0m       trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:666\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m     tf_logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    662\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`caching_device` does not work with mixed precision API. Ignoring \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    663\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser specified `caching_device`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    664\u001b[0m     caching_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 666\u001b[0m variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_variable_with_custom_getter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# `Trackable` method.\u001b[39;49;00m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgetter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgetter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regularizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    684\u001b[0m   \u001b[38;5;66;03m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[0;32m    685\u001b[0m   \u001b[38;5;66;03m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[0;32m    686\u001b[0m   \u001b[38;5;66;03m# should be variable attributes.\u001b[39;00m\n\u001b[0;32m    687\u001b[0m   name_in_scope \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mname[:variable\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:813\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    803\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (checkpoint_initializer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    804\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    805\u001b[0m            (initializer\u001b[38;5;241m.\u001b[39mrestore_uid \u001b[38;5;241m>\u001b[39m checkpoint_initializer\u001b[38;5;241m.\u001b[39mrestore_uid))):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;66;03m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;66;03m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m     initializer \u001b[38;5;241m=\u001b[39m checkpoint_initializer\n\u001b[1;32m--> 813\u001b[0m new_variable \u001b[38;5;241m=\u001b[39m getter(\n\u001b[0;32m    814\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    815\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[0;32m    816\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    817\u001b[0m     initializer\u001b[38;5;241m=\u001b[39minitializer,\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_for_getter)\n\u001b[0;32m    820\u001b[0m \u001b[38;5;66;03m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;66;03m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# handles slot variables.\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py:127\u001b[0m, in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# TODO(apassos,rohanj) figure out how to remove collections from here so we\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# can remove the V1.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m variable_shape \u001b[38;5;241m=\u001b[39m tensor_shape\u001b[38;5;241m.\u001b[39mTensorShape(shape)\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_variables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariableV1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvariable_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:266\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    265\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m VariableV1:\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_v1_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    267\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Variable:\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_v2_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:212\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aggregation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m   aggregation \u001b[38;5;241m=\u001b[39m VariableAggregation\u001b[38;5;241m.\u001b[39mNONE\n\u001b[1;32m--> 212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprevious_getter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariable_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimport_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:205\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call.<locals>.<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_variable_v1_call\u001b[39m(\u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m    189\u001b[0m                       initial_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    190\u001b[0m                       trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m                       aggregation\u001b[38;5;241m=\u001b[39mVariableAggregation\u001b[38;5;241m.\u001b[39mNONE,\n\u001b[0;32m    203\u001b[0m                       shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    204\u001b[0m   \u001b[38;5;124;03m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 205\u001b[0m   previous_getter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: default_variable_creator(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m _, getter \u001b[38;5;129;01min\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39m_variable_creator_stack:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    207\u001b[0m     previous_getter \u001b[38;5;241m=\u001b[39m _make_getter(getter, previous_getter)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py:2612\u001b[0m, in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_resource:\n\u001b[0;32m   2611\u001b[0m   distribute_strategy \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistribute_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 2612\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResourceVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2613\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2614\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2615\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2616\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2617\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2618\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2619\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2620\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2621\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvariable_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2622\u001b[0m \u001b[43m      \u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimport_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2623\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2624\u001b[0m \u001b[43m      \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2625\u001b[0m \u001b[43m      \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2626\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2627\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2628\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mRefVariable(\n\u001b[0;32m   2629\u001b[0m       initial_value\u001b[38;5;241m=\u001b[39minitial_value,\n\u001b[0;32m   2630\u001b[0m       trainable\u001b[38;5;241m=\u001b[39mtrainable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2641\u001b[0m       aggregation\u001b[38;5;241m=\u001b[39maggregation,\n\u001b[0;32m   2642\u001b[0m       shape\u001b[38;5;241m=\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:270\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_v2_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(VariableMetaclass, \u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1602\u001b[0m, in \u001b[0;36mResourceVariable.__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1600\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_from_proto(variable_def, import_scope\u001b[38;5;241m=\u001b[39mimport_scope)\n\u001b[0;32m   1601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1602\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_from_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1603\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1604\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1605\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1606\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m      \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m      \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1740\u001b[0m, in \u001b[0;36mResourceVariable._init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializer\u001b[39m\u001b[38;5;124m\"\u001b[39m), device_context_manager(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1739\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m init_from_fn:\n\u001b[1;32m-> 1740\u001b[0m     initial_value \u001b[38;5;241m=\u001b[39m \u001b[43minitial_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1741\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(initial_value, trackable\u001b[38;5;241m.\u001b[39mCheckpointInitialValue):\n\u001b[0;32m   1742\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v2.py:523\u001b[0m, in \u001b[0;36mVarianceScaling.__call__\u001b[1;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    522\u001b[0m   limit \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m \u001b[38;5;241m*\u001b[39m scale)\n\u001b[1;32m--> 523\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_random_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_uniform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v2.py:978\u001b[0m, in \u001b[0;36m_RandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m   op \u001b[38;5;241m=\u001b[39m random_ops\u001b[38;5;241m.\u001b[39mrandom_uniform\n\u001b[1;32m--> 978\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py:309\u001b[0m, in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    306\u001b[0m   result \u001b[38;5;241m=\u001b[39m gen_random_ops\u001b[38;5;241m.\u001b[39mrandom_uniform_int(\n\u001b[0;32m    307\u001b[0m       shape, minval, maxval, seed\u001b[38;5;241m=\u001b[39mseed1, seed2\u001b[38;5;241m=\u001b[39mseed2, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 309\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_random_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m minval_is_zero:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m maxval_is_one:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py:720\u001b[0m, in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[0;32m    718\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 720\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m    722\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m message \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6940\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 6941\u001b[0m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_status_to_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[43264,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "AlexNet = tf.keras.models.load_model('AlexNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1034fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simplified\n",
    "\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(32, kernel_size=(5,5), strides=(2,2), padding='same', activation = 'relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size = (3,3), strides=(2,2))(x)\n",
    "x = layers.Conv2D(238, kernel_size=(5,5), padding='same', activation = 'relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size = (3,3), strides=(2,2))(x)\n",
    "x = layers.Conv2D(256, kernel_size=(3,3), padding='same', activation = 'relu')(inputs)\n",
    "x = layers.Conv2D(128, kernel_size=(3,3), padding='same', activation = 'relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size = (3,3), strides=(2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(2048, activation='relu')(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "outputs = layers.Dense(10)(x) \n",
    "modelp4 = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b4ec20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 28, 28, 128)       1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 2048)              44304384  \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 46,414,090\n",
      "Trainable params: 46,414,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelp4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b73d1ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.3900 - accuracy: 0.8595 - val_loss: 0.2977 - val_accuracy: 0.8904\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2643 - accuracy: 0.9037 - val_loss: 0.2754 - val_accuracy: 0.9001\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2158 - accuracy: 0.9191 - val_loss: 0.2567 - val_accuracy: 0.9059\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1835 - accuracy: 0.9312 - val_loss: 0.2582 - val_accuracy: 0.9103\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1581 - accuracy: 0.9397 - val_loss: 0.2560 - val_accuracy: 0.9171\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1374 - accuracy: 0.9490 - val_loss: 0.3093 - val_accuracy: 0.9115\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1212 - accuracy: 0.9558 - val_loss: 0.3470 - val_accuracy: 0.9101\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1115 - accuracy: 0.9596 - val_loss: 0.3376 - val_accuracy: 0.9143\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0952 - accuracy: 0.9649 - val_loss: 0.3449 - val_accuracy: 0.9089\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0862 - accuracy: 0.9686 - val_loss: 0.3898 - val_accuracy: 0.9113\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0786 - accuracy: 0.9712 - val_loss: 0.4231 - val_accuracy: 0.9115\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0689 - accuracy: 0.9755 - val_loss: 0.4475 - val_accuracy: 0.9085\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0671 - accuracy: 0.9765 - val_loss: 0.5203 - val_accuracy: 0.9103\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0679 - accuracy: 0.9775 - val_loss: 0.4363 - val_accuracy: 0.9122\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0587 - accuracy: 0.9806 - val_loss: 0.4729 - val_accuracy: 0.9125\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0562 - accuracy: 0.9808 - val_loss: 0.4732 - val_accuracy: 0.9128\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0483 - accuracy: 0.9830 - val_loss: 0.5815 - val_accuracy: 0.9064\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0490 - accuracy: 0.9842 - val_loss: 0.5882 - val_accuracy: 0.9088\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0512 - accuracy: 0.9838 - val_loss: 0.6028 - val_accuracy: 0.9083\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0418 - accuracy: 0.9865 - val_loss: 0.6600 - val_accuracy: 0.9147\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0417 - accuracy: 0.9866 - val_loss: 0.6517 - val_accuracy: 0.9140\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0383 - accuracy: 0.9875 - val_loss: 0.6875 - val_accuracy: 0.9118\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0423 - accuracy: 0.9881 - val_loss: 0.7078 - val_accuracy: 0.9141\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0370 - accuracy: 0.9885 - val_loss: 0.6399 - val_accuracy: 0.9145\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 0.7232 - val_accuracy: 0.9138\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0405 - accuracy: 0.9885 - val_loss: 0.7596 - val_accuracy: 0.9079\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0345 - accuracy: 0.9893 - val_loss: 0.8253 - val_accuracy: 0.9138\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0411 - accuracy: 0.9891 - val_loss: 0.7909 - val_accuracy: 0.9099\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0328 - accuracy: 0.9898 - val_loss: 0.8099 - val_accuracy: 0.9103\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0317 - accuracy: 0.9910 - val_loss: 0.7266 - val_accuracy: 0.9115\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0366 - accuracy: 0.9903 - val_loss: 0.7907 - val_accuracy: 0.9136\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0415 - accuracy: 0.9898 - val_loss: 0.7405 - val_accuracy: 0.9123\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.8640 - val_accuracy: 0.9093\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0347 - accuracy: 0.9904 - val_loss: 0.8420 - val_accuracy: 0.9166\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0285 - accuracy: 0.9920 - val_loss: 0.9868 - val_accuracy: 0.9107\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0292 - accuracy: 0.9920 - val_loss: 1.2168 - val_accuracy: 0.9074\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0391 - accuracy: 0.9907 - val_loss: 0.7888 - val_accuracy: 0.9137\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0258 - accuracy: 0.9930 - val_loss: 1.1707 - val_accuracy: 0.9118\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0387 - accuracy: 0.9905 - val_loss: 0.8918 - val_accuracy: 0.9123\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0282 - accuracy: 0.9928 - val_loss: 0.8588 - val_accuracy: 0.9140\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0332 - accuracy: 0.9919 - val_loss: 1.0298 - val_accuracy: 0.9120\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 1.1299 - val_accuracy: 0.9101\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0267 - accuracy: 0.9933 - val_loss: 0.9141 - val_accuracy: 0.9145\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0404 - accuracy: 0.9917 - val_loss: 0.9324 - val_accuracy: 0.9163\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.9784 - val_accuracy: 0.9100\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0253 - accuracy: 0.9935 - val_loss: 1.1740 - val_accuracy: 0.9077\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0348 - accuracy: 0.9919 - val_loss: 0.9109 - val_accuracy: 0.9106\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0293 - accuracy: 0.9927 - val_loss: 0.9401 - val_accuracy: 0.9160\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0295 - accuracy: 0.9932 - val_loss: 1.0306 - val_accuracy: 0.9111\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0377 - accuracy: 0.9918 - val_loss: 0.9576 - val_accuracy: 0.9118\n"
     ]
    }
   ],
   "source": [
    "modelp4.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# compile and train model 5.\n",
    "train_hist = modelp4.fit(train_images, train_labels, \n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b213c44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 1.0208 - accuracy: 0.9081\n",
      "\n",
      "Test accuracy: 0.9081000089645386\n",
      "FLOPS: 94923914\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = modelp4.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "flops = get_flops(modelp4, batch_size=1)\n",
    "print(f\"FLOPS: {flops}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882853f6",
   "metadata": {},
   "source": [
    "Problem 5 (Extra 20 Bonus points)\n",
    "\n",
    "Design a better model that works directly on 28 * 28 images with better accuracy than AlexNet, but with lower theoretical computational complexity (operation and parameter size). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b8255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See model above\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
